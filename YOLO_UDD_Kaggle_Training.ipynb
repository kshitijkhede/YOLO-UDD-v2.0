{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d57864",
   "metadata": {},
   "source": [
    "# üåä YOLO-UDD v2.0 Training on Kaggle\n",
    "\n",
    "**Turbidity-Adaptive Underwater Debris Detection**\n",
    "\n",
    "This notebook trains YOLO-UDD v2.0 on Kaggle with GPU acceleration.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Setup Instructions:\n",
    "\n",
    "1. **Enable GPU**: Settings ‚Üí Accelerator ‚Üí GPU P100 or T4\n",
    "2. **Enable Internet**: Settings ‚Üí Internet ‚Üí ON\n",
    "3. **Run all cells** in order\n",
    "4. **Training saves checkpoints** automatically - you can resume later!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4065193",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your repository\n",
    "!git clone https://github.com/kshitijkhede/YOLO-UDD-v2.0.git\n",
    "%cd YOLO-UDD-v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5896d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36833d3",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Upload Dataset Annotations\n",
    "\n",
    "**Option A: Upload from your computer (Recommended for first time)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your annotation files\n",
    "# You need to upload:\n",
    "# - train.json (22 MB)\n",
    "# - val.json (5.6 MB)\n",
    "\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Create annotations directory\n",
    "os.makedirs('data/trashcan/annotations', exist_ok=True)\n",
    "\n",
    "print(\"üì§ Please upload train.json...\")\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "    !mv {filename} data/trashcan/annotations/train.json\n",
    "    \n",
    "print(\"üì§ Please upload val.json...\")\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "    !mv {filename} data/trashcan/annotations/val.json\n",
    "\n",
    "print(\"‚úÖ Annotations uploaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf37e1",
   "metadata": {},
   "source": [
    "**Option B: Load from Kaggle Dataset (After first upload)**\n",
    "\n",
    "After training once, save your dataset as a Kaggle Dataset, then use it in future runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2668070e",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Download TrashCAN Images\n",
    "\n",
    "Download the TrashCAN dataset images from the external source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a047c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: If you have dataset on Google Drive\n",
    "# Uncomment and use this:\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !cp -r /content/drive/MyDrive/trashcan_images/* data/trashcan/images/\n",
    "\n",
    "# Option B: Download from Kaggle dataset (recommended)\n",
    "# First, upload your images as a Kaggle dataset, then:\n",
    "\n",
    "!kaggle datasets download -d YOUR_USERNAME/trashcan-images\n",
    "!unzip -q trashcan-images.zip -d data/trashcan/\n",
    "\n",
    "print(\"‚úÖ Images downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8935ec",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12524999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset structure\n",
    "!python scripts/verify_dataset.py --dataset-dir data/trashcan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf28658",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Configure Training\n",
    "\n",
    "Optimized for Kaggle GPU (30 hours/week limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Create optimized config for Kaggle\n",
    "config = {\n",
    "    'data_dir': './data/trashcan',\n",
    "    'num_classes': 3,\n",
    "    'img_size': 640,\n",
    "    'batch_size': 16,  # Adjust based on GPU memory\n",
    "    'epochs': 100,  # Start with 100, resume later for more\n",
    "    'num_workers': 2,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 0.0001,\n",
    "    'lr_scheduler': 'cosine',\n",
    "    'min_lr': 1e-6,\n",
    "    'device': 'cuda',\n",
    "    'save_interval': 10,  # Save checkpoint every 10 epochs\n",
    "    'early_stopping_patience': 30,\n",
    "}\n",
    "\n",
    "# Save config\n",
    "with open('configs/kaggle_config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"‚úÖ Config created!\")\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f05988",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Start Training üöÄ\n",
    "\n",
    "**Important:** Training will save checkpoints every 10 epochs. You can stop and resume anytime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training from scratch\n",
    "!python scripts/train.py --config configs/kaggle_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ec42d5",
   "metadata": {},
   "source": [
    "### üìä Resume Training (if interrupted)\n",
    "\n",
    "If your session times out, run this to resume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f196fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest checkpoint\n",
    "import os\n",
    "import glob\n",
    "\n",
    "checkpoints = glob.glob('runs/*/checkpoints/last.pth')\n",
    "if checkpoints:\n",
    "    latest = max(checkpoints, key=os.path.getctime)\n",
    "    print(f\"üìÇ Resuming from: {latest}\")\n",
    "    !python scripts/train.py --config configs/kaggle_config.yaml --resume {latest}\n",
    "else:\n",
    "    print(\"‚ùå No checkpoint found. Starting fresh training...\")\n",
    "    !python scripts/train.py --config configs/kaggle_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf883f2",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Monitor Training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac164591",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccbd543",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "!python scripts/evaluate.py \\\n",
    "    --checkpoint runs/*/checkpoints/best.pth \\\n",
    "    --data-dir data/trashcan \\\n",
    "    --split val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10df4d1",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Test Detection on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77249a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detection on validation images\n",
    "!python scripts/detect.py \\\n",
    "    --checkpoint runs/*/checkpoints/best.pth \\\n",
    "    --source data/trashcan/images/val/ \\\n",
    "    --output results/ \\\n",
    "    --max-images 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "result_images = glob.glob('results/*.jpg')[:6]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_path in enumerate(result_images):\n",
    "    img = Image.open(img_path)\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f'Detection {idx+1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d1736f",
   "metadata": {},
   "source": [
    "## üîü Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the best model to your computer\n",
    "from google.colab import files\n",
    "import glob\n",
    "\n",
    "best_model = glob.glob('runs/*/checkpoints/best.pth')[0]\n",
    "print(f\"üì• Downloading: {best_model}\")\n",
    "files.download(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e65e25",
   "metadata": {},
   "source": [
    "## üíæ Save Checkpoint to Kaggle Output\n",
    "\n",
    "This saves your checkpoint so you can resume in the next session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dacec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy checkpoints to Kaggle output (persists between sessions)\n",
    "!mkdir -p /kaggle/working/checkpoints\n",
    "!cp -r runs/*/checkpoints/* /kaggle/working/checkpoints/\n",
    "print(\"‚úÖ Checkpoints saved to Kaggle output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de8104d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Training Summary\n",
    "\n",
    "After training, you'll see:\n",
    "- ‚úÖ Training/Validation loss curves\n",
    "- ‚úÖ mAP (mean Average Precision) metrics\n",
    "- ‚úÖ Sample detection results\n",
    "- ‚úÖ Saved model checkpoint\n",
    "\n",
    "**Expected Results (after 100 epochs):**\n",
    "- mAP@50: 50-60%\n",
    "- mAP@50:95: 30-35%\n",
    "\n",
    "**For better results:**\n",
    "- Resume training for 200-300 total epochs\n",
    "- Expected final mAP@50: 70-75%\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Multi-Session Training Strategy\n",
    "\n",
    "Since Kaggle gives 30 hours/week:\n",
    "\n",
    "1. **Session 1** (6 hours): Train 0-100 epochs ‚Üí Save checkpoint\n",
    "2. **Session 2** (6 hours): Resume 100-200 epochs ‚Üí Save checkpoint  \n",
    "3. **Session 3** (6 hours): Resume 200-300 epochs ‚Üí Final model!\n",
    "\n",
    "Each session saves progress automatically!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
