{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b34df9",
   "metadata": {},
   "source": [
    "# üöÄ YOLO-UDD v2.0 Training on Kaggle - Fixed Version\n",
    "\n",
    "**Last Updated:** November 2, 2025\n",
    "\n",
    "## üìã Prerequisites\n",
    "1. Upload **TrashCAN annotations** dataset to Kaggle\n",
    "2. Upload **TrashCAN images** dataset to Kaggle\n",
    "3. Enable **GPU** in notebook settings (T4 or P100)\n",
    "4. Enable **Internet** in notebook settings\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bf4842",
   "metadata": {},
   "source": [
    "## üîß Step 1: Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Clone repository\n",
    "if [ ! -d \"YOLO-UDD-v2.0\" ]; then\n",
    "    git clone https://github.com/kshitijkhede/YOLO-UDD-v2.0.git\n",
    "fi\n",
    "cd YOLO-UDD-v2.0\n",
    "echo \"‚úÖ Repository cloned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd YOLO-UDD-v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c59ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies with correct versions\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q opencv-python-headless pillow pycocotools pyyaml tqdm tensorboard\n",
    "!pip install -q albumentations timm scikit-learn\n",
    "\n",
    "print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c637903",
   "metadata": {},
   "source": [
    "## üìä Step 2: Setup Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "print(\"üîç Setting up dataset paths...\\n\")\n",
    "\n",
    "# Create directory structure\n",
    "os.makedirs('data/trashcan/annotations', exist_ok=True)\n",
    "os.makedirs('data/trashcan/images', exist_ok=True)\n",
    "\n",
    "# === MODIFY THESE PATHS TO MATCH YOUR KAGGLE DATASETS ===\n",
    "ANNOTATIONS_PATH = '/kaggle/input/trashcan-annotations-coco-format/annotations'\n",
    "IMAGES_PATH = '/kaggle/input/trashcan/images'\n",
    "\n",
    "# Alternative paths (uncomment and modify if needed)\n",
    "# ANNOTATIONS_PATH = '/kaggle/input/YOUR-ANNOTATIONS-DATASET-NAME/'\n",
    "# IMAGES_PATH = '/kaggle/input/YOUR-IMAGES-DATASET-NAME/'\n",
    "\n",
    "print(f\"Annotations source: {ANNOTATIONS_PATH}\")\n",
    "print(f\"Images source: {IMAGES_PATH}\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba393603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link annotations\n",
    "print(\"üìã Copying annotations...\")\n",
    "\n",
    "train_json = os.path.join(ANNOTATIONS_PATH, 'train.json')\n",
    "val_json = os.path.join(ANNOTATIONS_PATH, 'val.json')\n",
    "\n",
    "if os.path.exists(train_json) and os.path.exists(val_json):\n",
    "    shutil.copy(train_json, 'data/trashcan/annotations/train.json')\n",
    "    shutil.copy(val_json, 'data/trashcan/annotations/val.json')\n",
    "    \n",
    "    # Verify\n",
    "    with open('data/trashcan/annotations/train.json', 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    with open('data/trashcan/annotations/val.json', 'r') as f:\n",
    "        val_data = json.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Train: {len(train_data['images'])} images, {len(train_data['annotations'])} annotations\")\n",
    "    print(f\"‚úÖ Val: {len(val_data['images'])} images, {len(val_data['annotations'])} annotations\")\n",
    "    print(f\"‚úÖ Categories: {len(train_data['categories'])}\")\n",
    "else:\n",
    "    print(f\"‚ùå Annotations not found!\")\n",
    "    print(f\"   Looking for: {train_json}\")\n",
    "    print(f\"   Please update ANNOTATIONS_PATH in the cell above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73664a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link images (symbolic links to save space)\n",
    "print(\"üñºÔ∏è  Linking images...\")\n",
    "\n",
    "train_imgs_src = os.path.join(IMAGES_PATH, 'train')\n",
    "val_imgs_src = os.path.join(IMAGES_PATH, 'val')\n",
    "\n",
    "train_imgs_dst = 'data/trashcan/images/train'\n",
    "val_imgs_dst = 'data/trashcan/images/val'\n",
    "\n",
    "# Remove old links\n",
    "for path in [train_imgs_dst, val_imgs_dst]:\n",
    "    if os.path.exists(path):\n",
    "        if os.path.islink(path):\n",
    "            os.unlink(path)\n",
    "        else:\n",
    "            shutil.rmtree(path)\n",
    "\n",
    "# Create symbolic links\n",
    "if os.path.exists(train_imgs_src) and os.path.exists(val_imgs_src):\n",
    "    os.symlink(train_imgs_src, train_imgs_dst)\n",
    "    os.symlink(val_imgs_src, val_imgs_dst)\n",
    "    \n",
    "    train_count = len([f for f in os.listdir(train_imgs_dst) if f.endswith('.jpg')])\n",
    "    val_count = len([f for f in os.listdir(val_imgs_dst) if f.endswith('.jpg')])\n",
    "    \n",
    "    print(f\"‚úÖ Train images: {train_count}\")\n",
    "    print(f\"‚úÖ Val images: {val_count}\")\n",
    "    \n",
    "    if train_count > 0 and val_count > 0:\n",
    "        print(\"\\nüéâ Dataset is ready for training!\")\n",
    "else:\n",
    "    print(f\"‚ùå Images not found!\")\n",
    "    print(f\"   Looking for: {train_imgs_src}\")\n",
    "    print(f\"   Please update IMAGES_PATH in the cell above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5a93e0",
   "metadata": {},
   "source": [
    "## üîç Step 3: Verify GPU and PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: GPU not available!\")\n",
    "    print(\"   Go to Settings ‚Üí Accelerator ‚Üí Select GPU T4 or P100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff1ad0",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 4: Create Optimized Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Create optimized config for Kaggle\n",
    "config = {\n",
    "    'model': {\n",
    "        'name': 'YOLO-UDD-v2.0',\n",
    "        'num_classes': 22,\n",
    "        'pretrained_path': None\n",
    "    },\n",
    "    'data': {\n",
    "        'dataset_name': 'TrashCAN-1.0',\n",
    "        'data_dir': 'data/trashcan',\n",
    "        'img_size': 640,\n",
    "        'class_names': [\n",
    "            \"rov\", \"plant\", \"animal_fish\", \"animal_starfish\", \"animal_shells\",\n",
    "            \"animal_crab\", \"animal_eel\", \"animal_etc\", \"trash_clothing\", \"trash_pipe\",\n",
    "            \"trash_bottle\", \"trash_bag\", \"trash_snack_wrapper\", \"trash_can\", \"trash_cup\",\n",
    "            \"trash_container\", \"trash_unknown_instance\", \"trash_branch\", \"trash_wreckage\",\n",
    "            \"trash_tarp\", \"trash_rope\", \"trash_net\"\n",
    "        ]\n",
    "    },\n",
    "    'training': {\n",
    "        'epochs': 100,\n",
    "        'batch_size': 8,           # Optimized for T4 GPU\n",
    "        'num_workers': 2,\n",
    "        'optimizer': 'AdamW',\n",
    "        'learning_rate': 0.001,    # Lower initial LR for stability\n",
    "        'weight_decay': 0.0005,\n",
    "        'scheduler': 'CosineAnnealing',\n",
    "        'lr_min': 0.00001,\n",
    "        'early_stopping_patience': 30,\n",
    "        'grad_clip_norm': 10.0,\n",
    "        'use_amp': True            # Mixed precision\n",
    "    },\n",
    "    'loss': {\n",
    "        'lambda_box': 5.0,\n",
    "        'lambda_obj': 1.0,\n",
    "        'lambda_cls': 1.0,\n",
    "        'focal_loss_gamma': 2.0,\n",
    "        'iou_type': 'CIoU'\n",
    "    },\n",
    "    'augmentation': {\n",
    "        'use_augmentation': True,\n",
    "        'horizontal_flip_prob': 0.5,\n",
    "        'color_jitter': True,\n",
    "        'gaussian_blur': False,     # Disabled to reduce training time\n",
    "        'underwater_augmentation': True\n",
    "    },\n",
    "    'checkpoints': {\n",
    "        'save_dir': '/kaggle/working/checkpoints',\n",
    "        'save_interval': 10,\n",
    "        'save_best_only': False\n",
    "    },\n",
    "    'logging': {\n",
    "        'use_tensorboard': True,\n",
    "        'log_dir': '/kaggle/working/runs',\n",
    "        'log_interval': 50\n",
    "    },\n",
    "    'eval': {\n",
    "        'conf_threshold': 0.001,\n",
    "        'nms_threshold': 0.6,\n",
    "        'eval_interval': 5\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save config\n",
    "os.makedirs('configs', exist_ok=True)\n",
    "with open('configs/kaggle_config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"‚úÖ Training config created!\")\n",
    "print(\"\\nKey settings:\")\n",
    "print(f\"  - Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"  - Epochs: {config['training']['epochs']}\")\n",
    "print(f\"  - Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"  - Image size: {config['data']['img_size']}\")\n",
    "print(f\"  - Mixed precision: {config['training']['use_amp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06cfa09",
   "metadata": {},
   "source": [
    "## üöÄ Step 5: Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafa2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Check for existing checkpoints to resume\n",
    "checkpoint_dir = '/kaggle/working/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoints = glob.glob(f'{checkpoint_dir}/*.pth')\n",
    "\n",
    "if checkpoints:\n",
    "    latest_ckpt = max(checkpoints, key=os.path.getctime)\n",
    "    print(f\"üîÑ Found checkpoint: {latest_ckpt}\")\n",
    "    print(\"   Will resume training from this checkpoint\\n\")\n",
    "    resume_flag = f\"--resume {latest_ckpt}\"\n",
    "else:\n",
    "    print(\"üÜï No previous checkpoint found\")\n",
    "    print(\"   Starting fresh training\\n\")\n",
    "    resume_flag = \"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ Starting YOLO-UDD v2.0 Training\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12504dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "!python scripts/train.py --config configs/kaggle_config.yaml {resume_flag}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0217e3f3",
   "metadata": {},
   "source": [
    "## üíæ Step 6: Save Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"üíæ Saving checkpoints...\\n\")\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs('/kaggle/working/checkpoints', exist_ok=True)\n",
    "\n",
    "# Find all checkpoint files\n",
    "run_checkpoints = glob.glob('runs/*/checkpoints/*.pth')\n",
    "\n",
    "if run_checkpoints:\n",
    "    for ckpt in run_checkpoints:\n",
    "        dest = os.path.join('/kaggle/working/checkpoints', os.path.basename(ckpt))\n",
    "        shutil.copy(ckpt, dest)\n",
    "        size = os.path.getsize(dest) / (1024*1024)\n",
    "        print(f\"‚úÖ Saved: {os.path.basename(ckpt)} ({size:.1f} MB)\")\n",
    "    \n",
    "    print(f\"\\nüì¶ Total checkpoints: {len(run_checkpoints)}\")\n",
    "    print(\"‚úÖ Checkpoints saved to /kaggle/working/checkpoints/\")\n",
    "    print(\"\\nüí° These checkpoints will persist between Kaggle sessions!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No checkpoints found to save\")\n",
    "    print(\"   Training may not have started or completed any epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc213298",
   "metadata": {},
   "source": [
    "## üìä Step 7: View Training Logs (TensorBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1565c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /kaggle/working/runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c94239a",
   "metadata": {},
   "source": [
    "## üéØ Step 8: Evaluate Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cba062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best checkpoint\n",
    "import glob\n",
    "\n",
    "best_ckpt = glob.glob('/kaggle/working/checkpoints/best.pth')\n",
    "\n",
    "if best_ckpt:\n",
    "    print(f\"üìä Evaluating model: {best_ckpt[0]}\\n\")\n",
    "    !python scripts/evaluate.py \\\n",
    "        --checkpoint {best_ckpt[0]} \\\n",
    "        --data-dir data/trashcan \\\n",
    "        --split val\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No 'best.pth' checkpoint found\")\n",
    "    print(\"   Training may still be in progress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44dfed",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Step 9: Run Detection on Sample Images (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd28665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detection on validation images\n",
    "import glob\n",
    "\n",
    "best_ckpt = glob.glob('/kaggle/working/checkpoints/best.pth')\n",
    "\n",
    "if best_ckpt:\n",
    "    print(f\"üéØ Running detection with: {best_ckpt[0]}\\n\")\n",
    "    !python scripts/detect.py \\\n",
    "        --checkpoint {best_ckpt[0]} \\\n",
    "        --source data/trashcan/images/val/ \\\n",
    "        --output /kaggle/working/results/ \\\n",
    "        --max-images 10\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No checkpoint found for detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a2eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detection results\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "result_images = glob.glob('/kaggle/working/results/*.jpg')[:6]\n",
    "\n",
    "if result_images:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, img_path in enumerate(result_images):\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f'Detection {idx+1}')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(result_images), 6):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No detection results found\")\n",
    "    print(\"   Run the detection cell above first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957bfa64",
   "metadata": {},
   "source": [
    "## üì• Step 10: Download Checkpoints (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available checkpoints\n",
    "import glob\n",
    "import os\n",
    "\n",
    "checkpoints = glob.glob('/kaggle/working/checkpoints/*.pth')\n",
    "\n",
    "if checkpoints:\n",
    "    print(\"üì¶ Available checkpoints:\\n\")\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        size = os.path.getsize(ckpt) / (1024*1024)\n",
    "        print(f\"  - {os.path.basename(ckpt)} ({size:.1f} MB)\")\n",
    "    \n",
    "    print(\"\\nüí° To download, you can:\")\n",
    "    print(\"  1. Use Kaggle's file browser (right sidebar)\")\n",
    "    print(\"  2. Navigate to /kaggle/working/checkpoints/\")\n",
    "    print(\"  3. Right-click on files to download\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No checkpoints found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711bb6cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Training Complete!\n",
    "\n",
    "### Next Steps:\n",
    "1. **Download checkpoints** from `/kaggle/working/checkpoints/`\n",
    "2. **View TensorBoard** logs to analyze training\n",
    "3. **Run evaluation** to see final metrics\n",
    "4. **Test on new images** using `detect.py`\n",
    "\n",
    "### Tips for Better Results:\n",
    "- Train for more epochs (increase `epochs` in config)\n",
    "- Adjust learning rate if loss plateaus\n",
    "- Try different batch sizes based on GPU memory\n",
    "- Enable more augmentations for better generalization\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
