# YOLO-UDD v2.0 Training Guide

## ‚úÖ Successfully Tested Configuration

This project has been **successfully tested and working** on both CPU and GPU platforms. Training completes without errors.

---

## üñ•Ô∏è Local Training (Windows CPU)

### System Requirements
- **OS**: Windows 10/11
- **RAM**: 8GB minimum (tested with 8GB)
- **CPU**: Multi-core processor (tested with AMD Ryzen 5 5600H)
- **Storage**: 2GB free space

### Quick Start (Tested & Working ‚úÖ)

#### Step 1: Install Python & Dependencies

```powershell
# Use your existing Python installation (tested with Python 3.13.5 via Miniconda)
C:\ProgramData\miniconda3\python.exe --version

# Install PyTorch CPU version
C:\ProgramData\miniconda3\python.exe -m pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio

# Install project dependencies
C:\ProgramData\miniconda3\python.exe -m pip install opencv-python pillow albumentations tensorboard tqdm pyyaml scikit-learn matplotlib seaborn pandas scipy pycocotools
```

#### Step 2: Create Test Dataset

```powershell
# Generate a small dummy dataset for testing (10 train, 3 val images)
C:\ProgramData\miniconda3\python.exe scripts/create_dummy_dataset.py --output_dir data/trashcan --num_train 10 --num_val 3
```

#### Step 3: Run Training

```powershell
# CPU-optimized training (2 epochs for quick test)
C:\ProgramData\miniconda3\python.exe scripts/train.py --config configs/train_config_cpu.yaml --epochs 2 --batch-size 1 --img-size 320 --num-workers 0 --device cpu
```

**Expected Results:**
- ‚úÖ Training completes without errors
- ‚è±Ô∏è Time: ~40 seconds for 2 epochs (10 images)
- üíæ Checkpoints saved to `runs/train_cpu/checkpoints/`

### For Real Training

Replace dummy dataset with your actual TrashCan dataset, then:

```powershell
# Full training with real data
C:\ProgramData\miniconda3\python.exe scripts/train.py ^
  --config configs/train_config_cpu.yaml ^
  --data-dir path/to/your/trashcan ^
  --epochs 50 ^
  --batch-size 1 ^
  --img-size 320 ^
  --num-workers 0 ^
  --device cpu
```

‚ö†Ô∏è **CPU Training Notes:**
- Training is **100x slower** than GPU (~10-20 hours for full dataset)
- Use `--img-size 320` instead of 640 to reduce memory and time
- Set `--batch-size 1` to avoid out-of-memory errors
- Consider training only 10-20 epochs initially to test

---

## ‚òÅÔ∏è Kaggle Training (GPU - Recommended)

### Method 1: Using Helper Script (Easiest)

After cloning the repo in Kaggle, run this in a notebook cell:

```python
!python scripts/run_kaggle_training.py \
    --data-dir /kaggle/working/trashcan \
    --epochs 100 \
    --batch-size 8 \
    --lr 0.01
```

**What it does:**
- ‚úÖ Checks/fixes NumPy compatibility (downgrades NumPy 2.x to 1.26.4)
- ‚úÖ Installs missing dependencies (albumentations, pycocotools, gdown, etc.)
- ‚úÖ Auto-detects GPU availability
- ‚úÖ Falls back to CPU-safe defaults if no GPU
- ‚úÖ Locates dataset annotation files automatically
- ‚úÖ Runs training and captures detailed error output

If NumPy 2.x is detected, the script will:
1. Install NumPy 1.26.4
2. Exit and ask you to restart the kernel
3. Re-run the cell after restart

### Method 2: Direct Training

```python
!python scripts/train.py \
    --config configs/train_config.yaml \
    --data-dir /kaggle/working/trashcan \
    --batch-size 8 \
    --epochs 100 \
    --lr 0.01 \
    --img-size 640 \
    --num-workers 2
```

### Kaggle Notebook Setup

1. **Enable GPU**: Settings ‚Üí Accelerator ‚Üí **GPU T4 x2**
2. **Clone repo**:
   ```python
   !git clone https://github.com/kshitijkhede/YOLO-UDD-v2.0.git
   %cd YOLO-UDD-v2.0
   ```
3. **Download dataset** (use gdown or upload to Kaggle datasets)
4. **Run training** using Method 1 or 2 above

---

## üõ†Ô∏è New Features Added

### Enhanced CLI Flags

The training script now supports additional flags for easier configuration:

```powershell
python scripts/train.py \
  --config configs/train_config_cpu.yaml \
  --data-dir data/trashcan \
  --batch-size 1 \
  --epochs 10 \
  --lr 0.001 \
  --img-size 320 \          # NEW: Override image size
  --num-workers 0 \         # NEW: Control dataloader workers
  --device cpu \            # NEW: Force CPU or CUDA
  --pretrained path.pt \
  --save-dir runs/train
```

### CPU-Optimized Config

Created `configs/train_config_cpu.yaml` with safe defaults:
- `img_size: 320` (vs 640 for GPU)
- `batch_size: 1` (vs 16 for GPU)
- `num_workers: 0` (avoid Windows multiprocessing issues)
- `use_amp: false` (AMP only works on GPU)
- `epochs: 10` (for quick testing)

---

## üìä Training Results

### Test Run (Dummy Dataset)
- **Platform**: Windows 11, AMD Ryzen 5 5600H, 8GB RAM
- **Dataset**: 10 train + 3 val synthetic images
- **Config**: CPU-optimized (320px, batch=1)
- **Duration**: 40 seconds for 2 epochs
- **Status**: ‚úÖ **Completed successfully**

### Expected Performance (Real Dataset)

| Platform | GPU | Batch Size | Image Size | Epochs | Time | Expected mAP |
|----------|-----|------------|------------|--------|------|--------------|
| Kaggle | T4 x2 | 8-16 | 640 | 100 | ~10 hours | 70-72% |
| Local CPU | None | 1 | 320 | 50 | ~15-20 hours | 60-65% |
| Local CPU | None | 1 | 320 | 10 | ~3-4 hours | 40-50% |

---

## üêõ Common Issues & Solutions

### Issue 1: NumPy 2.x Compatibility
**Error**: `AttributeError` or crashes when importing TensorFlow/scikit-learn

**Solution**:
```powershell
C:\ProgramData\miniconda3\python.exe -m pip uninstall -y numpy
C:\ProgramData\miniconda3\python.exe -m pip install numpy==1.26.4
# Restart kernel/terminal
```

### Issue 2: Out of Memory (CPU)
**Error**: `RuntimeError: out of memory`

**Solutions**:
- Reduce batch size: `--batch-size 1`
- Reduce image size: `--img-size 256` or `--img-size 320`
- Set workers to 0: `--num-workers 0`

### Issue 3: Slow Training
**This is normal for CPU!** CPU training is 50-100x slower than GPU.

**Options**:
- Use Kaggle/Colab with GPU (free)
- Use smaller dataset for testing
- Train for fewer epochs (10-20 instead of 100)
- Use pretrained weights: `--pretrained path/to/weights.pt`

### Issue 4: Dataset Not Found
**Error**: `FileNotFoundError: Dataset not found`

**Solution**: Ensure dataset structure matches:
```
data/trashcan/
‚îú‚îÄ‚îÄ instances_train_trashcan.json
‚îú‚îÄ‚îÄ instances_val_trashcan.json
‚îî‚îÄ‚îÄ images/
    ‚îú‚îÄ‚îÄ train/
    ‚îî‚îÄ‚îÄ val/
```

Or use the helper script which auto-detects annotation files.

### Issue 5: Module Import Errors (Kaggle)
**Error**: `ModuleNotFoundError: No module named 'pycocotools'`

**Solution**: Use the helper script (`run_kaggle_training.py`) which auto-installs missing packages, or:
```python
!pip install pycocotools albumentations opencv-python-headless tensorboard gdown
```

---

## üí° Training Tips

### For Fast Iteration (Testing)
```powershell
# Use dummy dataset + few epochs
python scripts/create_dummy_dataset.py --num_train 20 --num_val 5
python scripts/train.py --config configs/train_config_cpu.yaml --epochs 5
```

### For Production Training
1. **Use GPU** (Kaggle/Colab/Cloud) - 100x faster
2. **Use pretrained weights** - converges faster
3. **Start with small epochs** (20-30) to validate setup
4. **Monitor tensorboard**: `tensorboard --logdir runs/train_cpu/logs`

### For Low-Memory Systems
- Set `img_size=256`, `batch_size=1`, `num_workers=0`
- Close other applications
- Use fewer data augmentations (edit config YAML)

---

## üìù File Reference

| File | Purpose |
|------|---------|
| `scripts/train.py` | Main training script (enhanced with new CLI flags) |
| `scripts/run_kaggle_training.py` | Kaggle helper script (auto-setup) |
| `configs/train_config.yaml` | GPU training config (original) |
| `configs/train_config_cpu.yaml` | CPU-optimized config (new) |
| `scripts/create_dummy_dataset.py` | Generate test dataset |

---

## ‚úÖ Verified Working Commands

These commands have been **tested and verified** on Windows 11:

```powershell
# 1. Install dependencies
C:\ProgramData\miniconda3\python.exe -m pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio
C:\ProgramData\miniconda3\python.exe -m pip install opencv-python pillow albumentations tensorboard tqdm pyyaml scikit-learn matplotlib seaborn pandas scipy pycocotools

# 2. Create test dataset
C:\ProgramData\miniconda3\python.exe scripts/create_dummy_dataset.py --output_dir data/trashcan --num_train 10 --num_val 3

# 3. Run training
C:\ProgramData\miniconda3\python.exe scripts/train.py --config configs/train_config_cpu.yaml --epochs 2 --batch-size 1 --img-size 320 --num-workers 0 --device cpu
```

**Result**: ‚úÖ Training completes in ~40 seconds without errors

---

## üéØ Next Steps

1. **Local Testing**: Run the verified commands above to test your setup
2. **Real Data**: Replace dummy dataset with your actual TrashCan dataset
3. **Kaggle Training**: Use `scripts/run_kaggle_training.py` for GPU training
4. **Monitor Progress**: Use TensorBoard to track metrics
5. **Evaluate**: Run `scripts/evaluate.py` on trained checkpoints

---

## üìß Support

- **GitHub Issues**: https://github.com/kshitijkhede/YOLO-UDD-v2.0/issues
- **Documentation**: See README.md for model architecture details
- **Training Debug**: This file contains all known issues and solutions

---

**Last Updated**: October 30, 2025  
**Status**: ‚úÖ Training verified working on Windows CPU and Kaggle GPU
