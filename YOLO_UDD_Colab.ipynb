{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# \ud83c\udf0a YOLO-UDD v2.0 - Underwater Debris Detection\n",
    "\n",
    "**Complete Training Pipeline on Google Colab with GPU** \u26a1 **OPTIMIZED**\n",
    "\n",
    "## \ud83d\ude80 Quick Start:\n",
    "1. **Upload Dataset**: Upload your TrashCAN dataset to Google Drive (COCO format supported)\n",
    "2. **Enable GPU**: Runtime \u2192 Change runtime type \u2192 GPU (T4 or better)\n",
    "3. **Update Path**: Dataset paths are pre-configured for `/content/drive/My Drive/trashcan_dataset/`\n",
    "4. **Run All**: Runtime \u2192 Run all (or run cells sequentially)\n",
    "5. **Monitor**: Training takes ~30-60 minutes depending on GPU and dataset size\n",
    "\n",
    "## \u26a1 Performance Optimizations:\n",
    "- **No dataset copying**: Uses symlinks (saves 5-10 minutes setup time)\n",
    "- **Direct Drive training**: Results saved directly to Drive in real-time\n",
    "- **Auto-save checkpoints**: Every epoch saved automatically\n",
    "- **Session-safe**: Results preserved even if Colab disconnects\n",
    "\n",
    "## \ud83d\udccb Prerequisites:\n",
    "- TrashCAN dataset uploaded to Google Drive at: `/content/drive/My Drive/trashcan_dataset/`\n",
    "- Dataset structure: COCO format with `instances_train_trashcan.json` and `instances_val_trashcan.json`\n",
    "- Images in `original_data/images/` folder\n",
    "- Sufficient Drive storage (~2-3 GB for dataset + checkpoints)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clone_repo",
    "outputId": "6f36b6d5-bcc4-4ab4-87d6-bcf11bf523ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'YOLO-UDD-v2.0'...\n",
      "remote: Enumerating objects: 113, done.\u001b[K\n",
      "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
      "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
      "remote: Total 113 (delta 43), reused 99 (delta 31), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (113/113), 83.24 KiB | 3.62 MiB/s, done.\n",
      "Resolving deltas: 100% (43/43), done.\n",
      "/content/YOLO-UDD-v2.0\n",
      "\n",
      "============================================================\n",
      "\u2713 Repository cloned successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Clone repository\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure we're in /content directory first\n",
    "try:\n",
    "    os.chdir('/content')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Remove existing directory if present\n",
    "if os.path.exists('/content/YOLO-UDD-v2.0'):\n",
    "    import shutil\n",
    "    shutil.rmtree('/content/YOLO-UDD-v2.0')\n",
    "    print(\"\u2713 Cleaned existing directory\")\n",
    "\n",
    "# Clone fresh\n",
    "print(\"Cloning repository...\")\n",
    "!git clone https://github.com/kshitijkhede/YOLO-UDD-v2.0.git /content/YOLO-UDD-v2.0\n",
    "\n",
    "# Verify clone succeeded\n",
    "if not os.path.exists('/content/YOLO-UDD-v2.0'):\n",
    "    raise FileNotFoundError(\"Failed to clone repository. Please check your internet connection.\")\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir('/content/YOLO-UDD-v2.0')\n",
    "sys.path.insert(0, '/content/YOLO-UDD-v2.0')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\u2713 Repository cloned successfully!\")\n",
    "print(f\"\u2713 Working directory: {os.getcwd()}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify repository structure\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83d\udcc2 Repository Structure\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "required_dirs = ['models', 'scripts', 'data', 'utils', 'configs']\n",
    "required_files = ['requirements.txt', 'models/__init__.py', 'scripts/train.py']\n",
    "\n",
    "for dir_name in required_dirs:\n",
    "    status = \"\u2713\" if os.path.exists(dir_name) else \"\u2717\"\n",
    "    print(f\"{status} {dir_name}/\")\n",
    "\n",
    "print()\n",
    "for file_name in required_files:\n",
    "    status = \"\u2713\" if os.path.exists(file_name) else \"\u2717\"\n",
    "    print(f\"{status} {file_name}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# List models package\n",
    "if os.path.exists('models'):\n",
    "    print(\"\\n\ud83d\udce6 Models package contents:\")\n",
    "    for item in os.listdir('models'):\n",
    "        print(f\"  - {item}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "check_gpu",
    "outputId": "be7f5f94-68b7-4dc8-e0b0-4b3f8bdb47fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GPU Status Check\n",
      "============================================================\n",
      "\u2713 GPU Available: Tesla T4\n",
      "\u2713 CUDA Version: 12.6\n",
      "\u2713 GPU Memory: 15.83 GB\n",
      "name, driver_version, memory.total [MiB]\n",
      "Tesla T4, 550.54.15, 15360 MiB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GPU Status Check\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\u2713 GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"\u2713 CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"\u2713 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  No GPU detected!\")\n",
    "    print(\"   Go to: Runtime \u2192 Change runtime type \u2192 GPU\")\n",
    "\n",
    "!nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.5: Mount Google Drive & Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and download dataset\n",
    "from google.colab import drive\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Mount Drive\n",
    "print(\"=\"*60)\n",
    "print(\"Mounting Google Drive...\")\n",
    "print(\"=\"*60)\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Download dataset from Google Drive using gdown\n",
    "GDRIVE_FILE_ID = '10PCbGqgVi0-XQn0EfGTTfSjwNS0JXR99'\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\ud83d\udce6 Downloading TrashCAN Dataset from Google Drive...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!pip install -q gdown\n",
    "!gdown --id {GDRIVE_FILE_ID} -O /content/trashcan.zip\n",
    "\n",
    "# Verify download\n",
    "if os.path.exists('/content/trashcan.zip'):\n",
    "    file_size = os.path.getsize('/content/trashcan.zip') / 1024 / 1024\n",
    "    print(f\"\\n\u2713 Downloaded: {file_size:.1f} MB\")\n",
    "    \n",
    "    # Extract dataset\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\ud83d\udcc2 Extracting dataset...\")\n",
    "    print(\"=\"*60)\n",
    "    !unzip -q /content/trashcan.zip -d /content/\n",
    "    \n",
    "    # Verify extraction\n",
    "    if os.path.exists('/content/trashcan'):\n",
    "        print(\"\u2705 Dataset extracted successfully!\")\n",
    "        \n",
    "        # Show structure\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"\ud83d\udccb Dataset Structure:\")\n",
    "        print(\"=\"*60)\n",
    "        for item in sorted(os.listdir('/content/trashcan')):\n",
    "            path = f'/content/trashcan/{item}'\n",
    "            if os.path.isdir(path):\n",
    "                count = len(os.listdir(path))\n",
    "                print(f\"  \ud83d\udcc1 {item}/ ({count} items)\")\n",
    "            else:\n",
    "                size = os.path.getsize(path) / 1024\n",
    "                print(f\"  \ud83d\udcc4 {item} ({size:.1f} KB)\")\n",
    "        \n",
    "        # Verify annotations\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"\ud83d\udd0d Verifying Annotations:\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for split in ['train', 'val']:\n",
    "            json_path = f'/content/trashcan/annotations/{split}.json'\n",
    "            if os.path.exists(json_path):\n",
    "                with open(json_path) as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                imgs = len(data.get('images', []))\n",
    "                anns = len(data.get('annotations', []))\n",
    "                cats = len(data.get('categories', []))\n",
    "                \n",
    "                print(f\"\\n  {split.upper()}:\")\n",
    "                print(f\"    Images:      {imgs:,}\")\n",
    "                print(f\"    Annotations: {anns:,}\")\n",
    "                print(f\"    Categories:  {cats}\")\n",
    "                \n",
    "                if anns > 0:\n",
    "                    print(f\"    \u2705 Ready for training!\")\n",
    "                else:\n",
    "                    print(f\"    \u274c ERROR: No annotations found!\")\n",
    "            else:\n",
    "                print(f\"\\n  \u274c {split.upper()}: File not found!\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"\u2705 Dataset setup complete!\")\n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"\u274c Extraction failed!\")\n",
    "        print(\"   Please check the ZIP file structure\")\n",
    "else:\n",
    "    print(\"\u274c Download failed!\")\n",
    "    print(\"   Please check the File ID and internet connection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "#VSC-path-fix-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move dataset to correct location for training scripts\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83d\udcc1 Moving dataset to correct location...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create the expected directory structure\n",
    "os.makedirs('/content/YOLO-UDD-v2.0/data', exist_ok=True)\n",
    "\n",
    "# Check if dataset is in /content/trashcan\n",
    "if os.path.exists('/content/trashcan'):\n",
    "    print(\"\u2713 Found dataset in /content/trashcan\")\n",
    "    \n",
    "    # Check if target exists and remove it\n",
    "    target = '/content/YOLO-UDD-v2.0/data/trashcan'\n",
    "    if os.path.exists(target):\n",
    "        print(\"\u2713 Removing old dataset at target location...\")\n",
    "        shutil.rmtree(target)\n",
    "    \n",
    "    # Move dataset to correct location\n",
    "    print(\"\u2713 Moving dataset to correct location...\")\n",
    "    shutil.move('/content/trashcan', target)\n",
    "    \n",
    "    # Verify the move\n",
    "    if os.path.exists(target):\n",
    "        print(f\"\\n\u2705 Dataset moved successfully to: {target}\")\n",
    "        \n",
    "        # Verify structure\n",
    "        if os.path.exists(f'{target}/images'):\n",
    "            imgs = [f for f in os.listdir(f'{target}/images') if f.endswith('.jpg')]\n",
    "            print(f\"   \ud83d\udcf8 Images: {len(imgs):,} files\")\n",
    "        \n",
    "        if os.path.exists(f'{target}/annotations'):\n",
    "            anns = os.listdir(f'{target}/annotations')\n",
    "            print(f\"   \ud83d\udccb Annotations: {len(anns)} files\")\n",
    "            \n",
    "            # Verify JSON contents\n",
    "            import json\n",
    "            for split in ['train', 'val']:\n",
    "                json_path = f'{target}/annotations/{split}.json'\n",
    "                if os.path.exists(json_path):\n",
    "                    with open(json_path) as f:\n",
    "                        data = json.load(f)\n",
    "                    print(f\"   \u2713 {split}.json: {len(data.get('annotations', [])):,} annotations\")\n",
    "        \n",
    "        print(\"\\n\u2705 Dataset is ready for training!\")\n",
    "    else:\n",
    "        print(\"\u274c Move failed!\")\n",
    "        \n",
    "elif os.path.exists('/content/YOLO-UDD-v2.0/data/trashcan'):\n",
    "    print(\"\u2705 Dataset already in correct location!\")\n",
    "    target = '/content/YOLO-UDD-v2.0/data/trashcan'\n",
    "    \n",
    "    # Verify it's good\n",
    "    if os.path.exists(f'{target}/images'):\n",
    "        imgs = [f for f in os.listdir(f'{target}/images') if f.endswith('.jpg')]\n",
    "        print(f\"   \ud83d\udcf8 Images: {len(imgs):,} files\")\n",
    "    \n",
    "    if os.path.exists(f'{target}/annotations/train.json'):\n",
    "        print(f\"   \u2713 train.json exists\")\n",
    "    if os.path.exists(f'{target}/annotations/val.json'):\n",
    "        print(f\"   \u2713 val.json exists\")\n",
    "    \n",
    "    print(\"\\n\u2705 Dataset is ready for training!\")\n",
    "else:\n",
    "    print(\"\u274c Dataset not found!\")\n",
    "    print(\"   Please re-run the dataset download cell above\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "install_deps",
    "outputId": "f2079347-9fc4-48b3-feba-ee8e87df55c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "\n",
      "============================================================\n",
      "\u2713 All dependencies installed successfully!\n",
      "\u2713 PyTorch: 2.8.0+cu126\n",
      "\u2713 Albumentations: 2.0.8\n",
      "\u2713 OpenCV: 4.12.0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Install all required packages\n",
    "print(\"Installing dependencies...\")\n",
    "\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q albumentations opencv-python-headless\n",
    "!pip install -q tensorboard pyyaml tqdm\n",
    "\n",
    "# Verify installations\n",
    "import torch\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\u2713 All dependencies installed successfully!\")\n",
    "print(f\"\u2713 PyTorch: {torch.__version__}\")\n",
    "print(f\"\u2713 Albumentations: {A.__version__}\")\n",
    "print(f\"\u2713 OpenCV: {cv2.__version__}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4"
   },
   "source": [
    "## Step 4: Test Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.5: Check GPU Memory & Clear Cache (Important for Training!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU memory status and clear cache\n",
    "import torch\n",
    "import gc\n",
    "import subprocess\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83d\udd0d GPU Memory Status Check\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Get GPU info\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    gpu_memory_allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    gpu_memory_reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    gpu_memory_free = gpu_memory_total - (gpu_memory_reserved)\n",
    "    \n",
    "    print(f\"GPU Device:       {gpu_name}\")\n",
    "    print(f\"Total Memory:     {gpu_memory_total:.2f} GB\")\n",
    "    print(f\"Allocated:        {gpu_memory_allocated:.2f} GB\")\n",
    "    print(f\"Reserved:         {gpu_memory_reserved:.2f} GB\")\n",
    "    print(f\"Free:             {gpu_memory_free:.2f} GB\")\n",
    "    \n",
    "    # Check for other processes using GPU\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"Checking for other GPU processes...\")\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-compute-apps=pid,used_memory', '--format=csv,noheader,nounits'], \n",
    "                              capture_output=True, text=True, timeout=5)\n",
    "        if result.stdout.strip():\n",
    "            print(\"\u26a0\ufe0f  Other processes using GPU:\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(\"\u2713 No other GPU processes detected\")\n",
    "    except:\n",
    "        print(\"\u2713 Could not check GPU processes (this is OK)\")\n",
    "    \n",
    "    # Clear GPU cache\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"Clearing GPU cache...\")\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Show memory after clearing\n",
    "    gpu_memory_allocated_after = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    gpu_memory_reserved_after = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    gpu_memory_free_after = gpu_memory_total - gpu_memory_reserved_after\n",
    "    \n",
    "    print(f\"After clearing:\")\n",
    "    print(f\"  Allocated:      {gpu_memory_allocated_after:.2f} GB (freed {gpu_memory_allocated - gpu_memory_allocated_after:.2f} GB)\")\n",
    "    print(f\"  Reserved:       {gpu_memory_reserved_after:.2f} GB (freed {gpu_memory_reserved - gpu_memory_reserved_after:.2f} GB)\")\n",
    "    print(f\"  Free:           {gpu_memory_free_after:.2f} GB\")\n",
    "    \n",
    "    # Warning if low memory\n",
    "    if gpu_memory_free_after < 8.0:\n",
    "        print(\"\\n\u26a0\ufe0f  WARNING: Low GPU memory available!\")\n",
    "        print(\"   You may encounter out-of-memory errors during training.\")\n",
    "        print(\"   Solutions:\")\n",
    "        print(\"   1. Restart runtime (Runtime \u2192 Restart runtime)\")\n",
    "        print(\"   2. Use smaller batch size (batch_size=2 or 4)\")\n",
    "        print(\"   3. Close other GPU-heavy notebooks\")\n",
    "    else:\n",
    "        print(\"\\n\u2713 GPU memory looks good for training!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  GPU not available - will use CPU (slower)\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "test_model",
    "outputId": "5e2a7500-4b01-428e-80c8-9b8d836d6323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building YOLO-UDD v2.0 model...\n",
      "\n",
      "============================================================\n",
      "YOLO-UDD v2.0 Model Information\n",
      "============================================================\n",
      "Architecture: YOLO-UDD v2.0\n",
      "Backbone: YOLOv9c\n",
      "Neck: PSEM-enhanced PANet + TAFM\n",
      "Head: SDWH\n",
      "Total Parameters: 60,627,051\n",
      "Trainable Parameters: 60,627,051\n",
      "Input Size: 640x640\n",
      "Output Classes: 3\n",
      "============================================================\n",
      "\n",
      "Testing forward pass...\n",
      "\n",
      "\u2713 Forward pass successful!\n",
      "\u2713 Number of detection scales: 3\n",
      "\u2713 Turbidity score shape: torch.Size([2, 1, 1, 1])\n",
      "\u2713 Device: cuda\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Import and test the model\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure we're in the repo directory and add to path\n",
    "repo_root = '/content/YOLO-UDD-v2.0'\n",
    "os.chdir(repo_root)\n",
    "sys.path.insert(0, repo_root)\n",
    "\n",
    "from models import build_yolo_udd\n",
    "import torch\n",
    "\n",
    "print(\"Building YOLO-UDD v2.0 model...\\n\")\n",
    "\n",
    "# Build model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = build_yolo_udd(num_classes=22, pretrained=None)\n",
    "model = model.to(device)\n",
    "\n",
    "# Get model info\n",
    "model_info = model.get_model_info()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"YOLO-UDD v2.0 Model Information\")\n",
    "print(\"=\"*60)\n",
    "for key, value in model_info.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nTesting forward pass...\")\n",
    "dummy_input = torch.randn(2, 3, 640, 640).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions, turb_score = model(dummy_input)\n",
    "\n",
    "print(f\"\\n\u2713 Forward pass successful!\")\n",
    "print(f\"\u2713 Number of detection scales: {len(predictions)}\")\n",
    "print(f\"\u2713 Turbidity score shape: {turb_score.shape}\")\n",
    "print(f\"\u2713 Device: {device}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5"
   },
   "source": [
    "## Step 5: Configure Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "config_training",
    "outputId": "a2d8b41e-0478-4eda-9338-100e051ebd92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\ud83d\ude80 Training Configuration\n",
      "============================================================\n",
      "Batch Size:     16\n",
      "Epochs:         10\n",
      "Learning Rate:  0.01\n",
      "Num Workers:    2\n",
      "Save Directory: runs/train\n",
      "Device:         GPU (CUDA)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Training configuration - Save to Drive\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU cache before training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"\u2713 Cleared GPU cache\")\n",
    "\n",
    "# OPTIMIZED SETTINGS for faster training\n",
    "BATCH_SIZE = 8       # Increased from 4 (faster training, still safe for most GPUs)\n",
    "EPOCHS = 100         # Reduced for faster training (still good results)\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_WORKERS = 4      # Increased from 2 for faster data loading\n",
    "\n",
    "# Save directly to Google Drive (preserves results even if session disconnects!)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "SAVE_DIR = f'/content/drive/MyDrive/YOLO-UDD-Results/run_{timestamp}'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83d\ude80 Training Configuration (SPEED OPTIMIZED)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Batch Size:     {BATCH_SIZE} (balanced for speed & memory)\")\n",
    "print(f\"Epochs:         {EPOCHS}\")\n",
    "print(f\"Learning Rate:  {LEARNING_RATE}\")\n",
    "print(f\"Num Workers:    {NUM_WORKERS} (increased for faster data loading)\")\n",
    "print(f\"Save Directory: {SAVE_DIR}\")\n",
    "print(f\"Device:         {'GPU (CUDA)' if torch.cuda.is_available() else 'CPU'}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    gpu_allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    gpu_reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    gpu_free = gpu_memory - gpu_reserved\n",
    "    print(f\"GPU Memory:     {gpu_memory:.2f} GB total, {gpu_free:.2f} GB free\")\n",
    "    \n",
    "    # Auto-adjust batch size based on available memory\n",
    "    if gpu_free < 6.0:\n",
    "        print(\"\\n\u26a0\ufe0f  Low GPU memory detected! Reducing batch size to 4...\")\n",
    "        BATCH_SIZE = 4\n",
    "    elif gpu_free > 10.0:\n",
    "        print(\"\\n\u2713 High GPU memory available! Batch size 8 is optimal\")\n",
    "    \n",
    "print(\"\\n\ud83d\udcbe Intermediate results will be saved to Drive automatically!\")\n",
    "print(\"   \u2713 Checkpoints saved after each epoch\")\n",
    "print(\"   \u2713 TensorBoard logs updated in real-time\")\n",
    "print(\"   \u2713 Results preserved even if session disconnects\")\n",
    "print(\"\\n\u26a1 Speed Optimizations Applied:\")\n",
    "print(\"   \u2713 Batch size: 8 (faster than 4, safer than 16)\")\n",
    "print(\"   \u2713 Workers: 4 (parallel data loading)\")\n",
    "print(\"   \u2713 GPU cache cleared before training\")\n",
    "print(\"\\n\u23f1\ufe0f  Estimated Training Time:\")\n",
    "iterations_per_epoch = 5769 // BATCH_SIZE\n",
    "total_time_minutes = (iterations_per_epoch * EPOCHS * 0.5) / 60  # ~0.5s per iteration\n",
    "print(f\"   \u2022 {iterations_per_epoch} iterations/epoch\")\n",
    "print(f\"   \u2022 ~{total_time_minutes:.1f} minutes for {EPOCHS} epochs on GPU\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6"
   },
   "source": [
    "## Step 6: Start Training \ud83c\udfaf\n",
    "\n",
    "**This will take approximately:**\n",
    "- GPU (T4): ~90-150 minutes for 300 epochs (full training)\n",
    "- GPU (V100): ~45-75 minutes for 300 epochs\n",
    "- GPU (A100): ~20-40 minutes for 300 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.75: Pre-Training Checklist (Run this before training to avoid slowdowns!) \u26a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.5: Verify Dataset (Optional - Run if training fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnose Dataset Issues\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83d\udd0d Dataset Diagnostic\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check dataset structure\n",
    "target_path = '/content/YOLO-UDD-v2.0/data/trashcan'\n",
    "print(f\"\\n\ud83d\udcc2 Dataset location: {target_path}\")\n",
    "print(f\"   Exists: {os.path.exists(target_path)}\")\n",
    "\n",
    "if os.path.exists(target_path):\n",
    "    print(f\"\\n\ud83d\udccb Contents:\")\n",
    "    for item in os.listdir(target_path):\n",
    "        path = os.path.join(target_path, item)\n",
    "        if os.path.isdir(path):\n",
    "            count = len(os.listdir(path))\n",
    "            print(f\"   \ud83d\udcc1 {item}/ ({count} items)\")\n",
    "        else:\n",
    "            size = os.path.getsize(path) / 1024\n",
    "            print(f\"   \ud83d\udcc4 {item} ({size:.1f} KB)\")\n",
    "\n",
    "# Check JSON files\n",
    "print(f\"\\n\ud83d\udd0e Analyzing COCO JSON files:\")\n",
    "for split in ['train', 'val']:\n",
    "    # Try the correct path first: annotations/train.json or annotations/val.json\n",
    "    json_path = os.path.join(target_path, 'annotations', f'{split}.json')\n",
    "    \n",
    "    # If not found, try the old naming convention\n",
    "    if not os.path.exists(json_path):\n",
    "        json_path = os.path.join(target_path, f'instances_{split}_trashcan.json')\n",
    "    \n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        images = data.get('images', [])\n",
    "        annotations = data.get('annotations', [])\n",
    "        categories = data.get('categories', [])\n",
    "        \n",
    "        print(f\"\\n  {split.upper()}:\")\n",
    "        print(f\"    JSON file: {os.path.basename(json_path)} \u2705\")\n",
    "        print(f\"    Images:      {len(images):,}\")\n",
    "        print(f\"    Annotations: {len(annotations):,}\")\n",
    "        print(f\"    Categories:  {len(categories)}\")\n",
    "        \n",
    "        if len(annotations) == 0:\n",
    "            print(f\"    \u26a0\ufe0f  WARNING: No annotations found!\")\n",
    "            if len(images) > 0:\n",
    "                print(f\"       Dataset has {len(images)} images but 0 annotations\")\n",
    "                print(f\"       This will cause training to fail\")\n",
    "        else:\n",
    "            print(f\"    \u2705 Ready for training!\")\n",
    "        \n",
    "        if len(categories) > 0:\n",
    "            cat_names = [c.get('name', 'unknown') for c in categories[:5]]\n",
    "            print(f\"    Sample categories: {cat_names}\")\n",
    "        \n",
    "        # Check image paths\n",
    "        if len(images) > 0:\n",
    "            sample_img = images[0]\n",
    "            img_filename = sample_img.get('file_name', '')\n",
    "            img_path = os.path.join(target_path, 'images', img_filename)\n",
    "            print(f\"    Sample image: {img_filename}\")\n",
    "            print(f\"    Image exists: {os.path.exists(img_path)}\")\n",
    "    else:\n",
    "        print(f\"\\n  {split.upper()}: \u274c JSON file not found\")\n",
    "        print(f\"    Expected: annotations/{split}.json\")\n",
    "        print(f\"    Or: instances_{split}_trashcan.json\")\n",
    "\n",
    "# Check images directory\n",
    "images_dir = os.path.join(target_path, 'images')\n",
    "if os.path.exists(images_dir):\n",
    "    all_files = os.listdir(images_dir)\n",
    "    image_files = [f for f in all_files if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    print(f\"\\n\ud83d\udcf8 Images directory:\")\n",
    "    print(f\"    Total files: {len(all_files)}\")\n",
    "    print(f\"    Image files: {len(image_files)}\")\n",
    "    if len(image_files) > 0:\n",
    "        print(f\"    Samples: {image_files[:3]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\ud83d\udca1 Diagnostic complete!\")\n",
    "print(\"   \u2713 If you see 'Ready for training!' above, you're good to go!\")\n",
    "print(\"   \u26a0\ufe0f  If annotations = 0, check your annotation files\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "run_training",
    "outputId": "27f6a5df-dd59-4e9e-8003-ee60f905a641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "\ud83d\ude80 Starting Training...\n",
      "============================================================\n",
      "Command: /usr/bin/python3 scripts/train.py --config configs/train_config.yaml --data-dir data/trashcan --batch-size 16 --epochs 10 --lr 0.01 --save-dir runs/train\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "\u26a0\ufe0f  Training ended with errors\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run training with progress monitoring\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Build command - CORRECTED VERSION\n",
    "cmd = [\n",
    "    sys.executable, 'scripts/train.py',\n",
    "    '--config', 'configs/train_config.yaml',\n",
    "    '--data-dir', 'data/trashcan',\n",
    "    '--batch-size', str(BATCH_SIZE),\n",
    "    '--epochs', str(EPOCHS),\n",
    "    '--lr', str(LEARNING_RATE),  # \u2190 Use --lr not --learning-rate\n",
    "    '--save-dir', SAVE_DIR\n",
    "]\n",
    "# NOTE: NO --num-workers argument - it's set in the config file!\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\ud83d\ude80 Starting Training...\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Track start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Run training with full output (to see any errors)\n",
    "try:\n",
    "    result = subprocess.run(cmd, check=True)\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    elapsed_minutes = elapsed_time / 60\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\u2713 Training completed successfully!\")\n",
    "    print(f\"\u2713 Total time: {elapsed_minutes:.1f} minutes ({elapsed_time:.0f} seconds)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except subprocess.CalledProcessError as e:\n",
    "    elapsed_time = time.time() - start_time\n",
    "    elapsed_minutes = elapsed_time / 60\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\u26a0\ufe0f  Training ended with errors\")\n",
    "    print(f\"\u26a0\ufe0f  Exit code: {e.returncode}\")\n",
    "    print(f\"\u26a0\ufe0f  Time before error: {elapsed_minutes:.1f} minutes\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Provide specific troubleshooting based on common errors\n",
    "    print(\"\\n\ud83d\udca1 Troubleshooting Tips:\")\n",
    "    if \"out of memory\" in str(e).lower() or e.returncode == 1:\n",
    "        print(\"   1. Reduce batch size to 4 or 2\")\n",
    "        print(\"   2. Restart runtime: Runtime \u2192 Restart runtime\")\n",
    "        print(\"   3. Check GPU status\")\n",
    "    elif \"file not found\" in str(e).lower():\n",
    "        print(\"   1. Run diagnostic cell to verify dataset\")\n",
    "        print(\"   2. Check dataset paths\")\n",
    "    else:\n",
    "        print(\"   1. Scroll up to see the full error message\")\n",
    "        print(\"   2. Check GPU memory\")\n",
    "        print(\"   3. Verify dataset\")\n",
    "    \n",
    "    print(\"\\n\ud83d\udca1 Tip: If taking too long, check:\")\n",
    "    print(\"   \u2022 GPU is enabled (Runtime \u2192 Change runtime type \u2192 GPU)\")\n",
    "    print(\"   \u2022 No other processes using GPU\")\n",
    "    print(\"   \u2022 Dataset images are loading correctly\")\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7"
   },
   "source": [
    "## Step 7: View Training Results \ud83d\udcca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "view_results",
    "outputId": "916747bf-9ca8-4cfc-9c66-7851bf01161c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training Results\n",
      "============================================================\n",
      "\u26a0\ufe0f  Checkpoint directory not found\n",
      "\n",
      "\ud83d\udcc1 Output Directory Structure:\n",
      "Directory not found\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Check for checkpoints\n",
    "checkpoint_dir = f'{SAVE_DIR}/checkpoints'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Training Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = glob.glob(f\"{checkpoint_dir}/*.pt\")\n",
    "    if checkpoints:\n",
    "        print(\"\\n\ud83d\udce6 Available Checkpoints:\")\n",
    "        for ckpt in sorted(checkpoints):\n",
    "            size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
    "            print(f\"   {os.path.basename(ckpt)}: {size_mb:.2f} MB\")\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f  No checkpoints found\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  Checkpoint directory not found\")\n",
    "\n",
    "# Show directory structure\n",
    "print(\"\\n\ud83d\udcc1 Output Directory Structure:\")\n",
    "!ls -lh {SAVE_DIR}/ 2>/dev/null || echo \"Directory not found\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## Step 8: Launch TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tensorboard"
   },
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {SAVE_DIR}/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step9"
   },
   "source": [
    "## Step 9: Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_model"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "best_model = f'{SAVE_DIR}/checkpoints/best.pt'\n",
    "latest_model = f'{SAVE_DIR}/checkpoints/latest.pt'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Download Models\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if os.path.exists(best_model):\n",
    "    size_mb = os.path.getsize(best_model) / (1024 * 1024)\n",
    "    print(f\"\\n\ud83d\udce5 Downloading best.pt ({size_mb:.2f} MB)...\")\n",
    "    files.download(best_model)\n",
    "    print(\"\u2713 Download complete!\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  best.pt not found\")\n",
    "\n",
    "if os.path.exists(latest_model):\n",
    "    size_mb = os.path.getsize(latest_model) / (1024 * 1024)\n",
    "    print(f\"\\n\ud83d\udce5 Downloading latest.pt ({size_mb:.2f} MB)...\")\n",
    "    files.download(latest_model)\n",
    "    print(\"\u2713 Download complete!\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  latest.pt not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step10"
   },
   "source": [
    "## Step 10: View Results in Google Drive \u2705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_to_drive"
   },
   "outputs": [],
   "source": [
    "# Results are already on Google Drive!\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83d\udcc1 Your Results on Google Drive\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# SAVE_DIR is already pointing to Drive from Step 5\n",
    "print(f\"\\n\u2713 All results saved to: {SAVE_DIR}\")\n",
    "print(\"\\n\ud83d\udce6 Contents:\")\n",
    "\n",
    "# List checkpoints\n",
    "checkpoint_dir = f'{SAVE_DIR}/checkpoints'\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = glob.glob(f\"{checkpoint_dir}/*.pt\")\n",
    "    if checkpoints:\n",
    "        print(\"\\n  Checkpoints:\")\n",
    "        for ckpt in sorted(checkpoints):\n",
    "            size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
    "            print(f\"    \u2022 {os.path.basename(ckpt)}: {size_mb:.2f} MB\")\n",
    "\n",
    "# List logs\n",
    "log_dir = f'{SAVE_DIR}/logs'\n",
    "if os.path.exists(log_dir):\n",
    "    print(f\"\\n  TensorBoard Logs: {log_dir}\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Access anytime from Google Drive:\")\n",
    "print(\"   My Drive \u2192 YOLO-UDD-Results \u2192 run_[timestamp]\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complete"
   },
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udf89 Training Complete!\n",
    "\n",
    "### What You've Done:\n",
    "- \u2705 Trained YOLO-UDD v2.0 on GPU\n",
    "- \u2705 Generated model checkpoints\n",
    "- \u2705 Created TensorBoard logs\n",
    "- \u2705 Downloaded trained models\n",
    "\n",
    "### Next Steps:\n",
    "1. **Use the model** for inference on new images\n",
    "2. **Evaluate performance** on test dataset\n",
    "3. **Fine-tune** by adjusting hyperparameters\n",
    "4. **Deploy** for real-world applications\n",
    "\n",
    "### Repository:\n",
    "https://github.com/kshitijkhede/YOLO-UDD-v2.0\n",
    "\n",
    "---\n",
    "\n",
    "**Need help?** Open an issue on GitHub or check the documentation.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}