{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a82cd800",
   "metadata": {},
   "source": [
    "# üåä YOLO-UDD v2.0 - Kaggle Training\n",
    "\n",
    "**Simple 6-Step Training - No Crashes, No Loops!** ‚ö°\n",
    "\n",
    "## üìã Before You Start:\n",
    "1. **Enable GPU**: Settings ‚Üí Accelerator ‚Üí **GPU T4 x2** ‚Üí Save\n",
    "2. **Dataset**: Google Drive link already configured (automatic download)\n",
    "3. **Run**: Execute cells 1-6 in order OR click \"Run All\"\n",
    "\n",
    "## ‚è±Ô∏è Training Info:\n",
    "- **Time**: ~10 hours (100 epochs)\n",
    "- **Expected mAP**: 70-72%\n",
    "- **No restarts needed!** ‚úÖ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830adbe",
   "metadata": {},
   "source": [
    "## Cell 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38942eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete environment setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîß CELL 1: Environment Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check and fix NumPy version FIRST (before any other imports)\n",
    "print(\"\\n[Step 1/3] Checking NumPy version...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_ver = np.__version__\n",
    "    \n",
    "    if numpy_ver.startswith('2.'):\n",
    "        print(f\"  ‚ö†Ô∏è  NumPy {numpy_ver} detected (will cause TensorFlow crashes)\")\n",
    "        print(\"  üîß Installing NumPy 1.26.4...\")\n",
    "        \n",
    "        # Use pip directly with quiet mode\n",
    "        !pip uninstall -y numpy > /dev/null 2>&1\n",
    "        !pip install -q numpy==1.26.4\n",
    "        \n",
    "        print(\"  ‚úÖ NumPy 1.26.4 installed\")\n",
    "        print(\"  ‚ÑπÔ∏è  If you see import errors later, just re-run this cell\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ NumPy {numpy_ver} OK\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö†Ô∏è  NumPy check issue: {e}\")\n",
    "    print(\"  üì¶ Installing NumPy 1.26.4...\")\n",
    "    !pip install -q numpy==1.26.4\n",
    "    print(\"  ‚úÖ Installed\")\n",
    "\n",
    "# Setup directories\n",
    "print(\"\\n[Step 2/3] Setting up directories...\")\n",
    "WORK_DIR = '/kaggle/working'\n",
    "REPO_DIR = f'{WORK_DIR}/YOLO-UDD-v2.0'\n",
    "\n",
    "os.chdir(WORK_DIR)\n",
    "print(f\"  ‚úÖ Working directory: {WORK_DIR}\")\n",
    "\n",
    "# Clone repository\n",
    "print(\"\\n[Step 3/3] Cloning repository...\")\n",
    "if os.path.exists(REPO_DIR):\n",
    "    import shutil\n",
    "    shutil.rmtree(REPO_DIR)\n",
    "\n",
    "!git clone -q https://github.com/kshitijkhede/YOLO-UDD-v2.0.git\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    os.chdir(REPO_DIR)\n",
    "    if REPO_DIR not in sys.path:\n",
    "        sys.path.insert(0, REPO_DIR)\n",
    "    print(f\"  ‚úÖ Repository ready: {REPO_DIR}\")\n",
    "else:\n",
    "    raise Exception(\"Clone failed!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Cell 1 Complete - Environment Ready!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42fbc1c",
   "metadata": {},
   "source": [
    "## Cell 2: Verify & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify setup and install dependencies\n",
    "import os\n",
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üì¶ CELL 2: Verification & Dependencies\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verify repository structure\n",
    "print(\"\\n[Step 1/3] Verifying repository...\")\n",
    "required = ['models/', 'scripts/', 'utils/', 'configs/', 'scripts/train.py']\n",
    "all_ok = True\n",
    "for item in required:\n",
    "    if os.path.exists(item):\n",
    "        print(f\"  ‚úÖ {item}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {item} MISSING\")\n",
    "        all_ok = False\n",
    "\n",
    "if not all_ok:\n",
    "    raise Exception(\"Repository incomplete! Re-run Cell 1\")\n",
    "\n",
    "# Check GPU\n",
    "print(\"\\n[Step 2/3] Checking GPU...\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  ‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  ‚úÖ Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"  ‚ùå NO GPU! Enable: Settings ‚Üí GPU T4 x2\")\n",
    "    raise RuntimeError(\"GPU required!\")\n",
    "\n",
    "# Install dependencies\n",
    "print(\"\\n[Step 3/3] Installing dependencies (this takes ~2 min)...\")\n",
    "!pip install -q torch>=2.0.0 torchvision>=0.15.0 albumentations>=1.3.0 \\\n",
    "    opencv-python-headless>=4.7.0 pycocotools>=2.0.6 tensorboard>=2.12.0 \\\n",
    "    tqdm pyyaml scikit-learn matplotlib seaborn\n",
    "\n",
    "print(\"  ‚úÖ Dependencies installed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Cell 2 Complete - System Ready!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc8028",
   "metadata": {},
   "source": [
    "## Cell 3: Setup Dataset\n",
    "\n",
    "**Dataset will download automatically from Google Drive (~170 MB, takes 2-3 min)**\n",
    "\n",
    "Alternative: Upload your own dataset to Kaggle and set `USE_KAGGLE_DATASET = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset setup\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üì¶ CELL 3: Dataset Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "USE_KAGGLE_DATASET = False  # Set True if you added dataset to Kaggle\n",
    "KAGGLE_DATASET_PATH = '/kaggle/input/trashcan-dataset'\n",
    "\n",
    "USE_GDRIVE = True  # ‚úÖ Default: Download from Google Drive\n",
    "GDRIVE_FILE_ID = '10PCbGqgVi0-XQn0EfGTTfSjwNS0JXR99'\n",
    "# ============================================\n",
    "\n",
    "DATASET_PATH = None\n",
    "\n",
    "if USE_KAGGLE_DATASET:\n",
    "    print(\"\\nüìÇ Using Kaggle Dataset...\")\n",
    "    if os.path.exists(KAGGLE_DATASET_PATH):\n",
    "        if os.path.isfile(KAGGLE_DATASET_PATH):\n",
    "            print(\"  üì¶ Extracting...\")\n",
    "            !unzip -q {KAGGLE_DATASET_PATH} -d /kaggle/working/\n",
    "            DATASET_PATH = '/kaggle/working/trashcan'\n",
    "        else:\n",
    "            trashcan = os.path.join(KAGGLE_DATASET_PATH, 'trashcan')\n",
    "            DATASET_PATH = trashcan if os.path.exists(trashcan) else KAGGLE_DATASET_PATH\n",
    "        print(f\"  ‚úÖ Dataset: {DATASET_PATH}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå NOT FOUND: {KAGGLE_DATASET_PATH}\")\n",
    "\n",
    "elif USE_GDRIVE:\n",
    "    print(\"\\n‚òÅÔ∏è  Downloading from Google Drive...\")\n",
    "    print(\"  üì¶ Installing gdown...\")\n",
    "    !pip install -q gdown\n",
    "    \n",
    "    print(\"  ‚¨áÔ∏è  Downloading dataset (~170 MB, 2-3 min)...\")\n",
    "    !gdown --id {GDRIVE_FILE_ID} -O /kaggle/working/trashcan.zip --quiet\n",
    "    \n",
    "    if os.path.exists('/kaggle/working/trashcan.zip'):\n",
    "        size = os.path.getsize('/kaggle/working/trashcan.zip') / 1024 / 1024\n",
    "        print(f\"  ‚úÖ Downloaded: {size:.1f} MB\")\n",
    "        \n",
    "        print(\"  üì¶ Extracting...\")\n",
    "        !unzip -q /kaggle/working/trashcan.zip -d /kaggle/working/\n",
    "        \n",
    "        if os.path.exists('/kaggle/working/trashcan'):\n",
    "            DATASET_PATH = '/kaggle/working/trashcan'\n",
    "            print(f\"  ‚úÖ Dataset: {DATASET_PATH}\")\n",
    "        else:\n",
    "            print(\"  ‚ùå Extraction failed\")\n",
    "    else:\n",
    "        print(\"  ‚ùå Download failed\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No method selected! Set USE_KAGGLE_DATASET or USE_GDRIVE = True\")\n",
    "\n",
    "# Verify dataset\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if DATASET_PATH and os.path.exists(DATASET_PATH):\n",
    "    print(f\"‚úÖ DATASET READY: {DATASET_PATH}\")\n",
    "    \n",
    "    # Count images\n",
    "    if os.path.exists(os.path.join(DATASET_PATH, 'images')):\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            img_path = os.path.join(DATASET_PATH, 'images', split)\n",
    "            if os.path.exists(img_path):\n",
    "                count = len([f for f in os.listdir(img_path) if f.endswith(('.jpg', '.png'))])\n",
    "                print(f\"  üìÅ {split}: {count:,} images\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ Cell 3 Complete - Dataset Ready!\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"‚ùå DATASET NOT READY!\")\n",
    "    raise Exception(\"Dataset setup failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5b365",
   "metadata": {},
   "source": [
    "## Cell 4: Build & Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ee2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and test YOLO-UDD model\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üèóÔ∏è  CELL 4: Build Model\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ensure correct paths\n",
    "REPO_DIR = '/kaggle/working/YOLO-UDD-v2.0'\n",
    "os.chdir(REPO_DIR)\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "print(\"\\n[Step 1/2] Building model...\")\n",
    "from models.yolo_udd import build_yolo_udd\n",
    "\n",
    "model = build_yolo_udd(num_classes=22)  # TrashCAN has 22 classes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"  ‚úÖ Model: YOLO-UDD v2.0\")\n",
    "print(f\"  ‚úÖ Classes: 22\")\n",
    "print(f\"  ‚úÖ Device: {device}\")\n",
    "print(f\"  ‚úÖ Parameters: {total_params:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\n[Step 2/2] Testing model...\")\n",
    "x = torch.randn(1, 3, 640, 640).to(device)\n",
    "with torch.no_grad():\n",
    "    predictions, turb_score = model(x)\n",
    "\n",
    "print(f\"  ‚úÖ Forward pass successful\")\n",
    "print(f\"  ‚úÖ Turbidity score: {turb_score.item():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Cell 4 Complete - Model Ready!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f0baad",
   "metadata": {},
   "source": [
    "## Cell 5: Start Training ‚ö°\n",
    "\n",
    "**‚è±Ô∏è This will take ~10 hours for 100 epochs**\n",
    "\n",
    "Training automatically:\n",
    "- Saves checkpoints every epoch\n",
    "- Shows progress with progress bar\n",
    "- Saves best model as `best.pt`\n",
    "- Results saved to `/kaggle/working/runs/train/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82fa8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and start training\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ CELL 5: TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Training configuration\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.01\n",
    "SAVE_DIR = '/kaggle/working/runs/train'\n",
    "\n",
    "print(f\"\\nüìä Configuration:\")\n",
    "print(f\"  ‚Ä¢ Epochs: {EPOCHS}\")\n",
    "print(f\"  ‚Ä¢ Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  ‚Ä¢ Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  ‚Ä¢ Dataset: {DATASET_PATH}\")\n",
    "print(f\"  ‚Ä¢ Save Dir: {SAVE_DIR}\")\n",
    "print(f\"\\n‚è±Ô∏è  Estimated Time: ~10 hours\")\n",
    "print(f\"üéØ Expected mAP: 70-72%\")\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ TRAINING STARTING...\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Run training with correct arguments\n",
    "!python scripts/train.py \\\n",
    "    --config configs/train_config.yaml \\\n",
    "    --data-dir {DATASET_PATH} \\\n",
    "    --epochs {EPOCHS} \\\n",
    "    --batch-size {BATCH_SIZE} \\\n",
    "    --lr {LEARNING_RATE} \\\n",
    "    --save-dir {SAVE_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701bf285",
   "metadata": {},
   "source": [
    "## Cell 6: Check Results & Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä CELL 6: Results\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if os.path.exists(SAVE_DIR):\n",
    "    print(f\"\\nüìÅ Results: {SAVE_DIR}\\n\")\n",
    "    \n",
    "    # List files\n",
    "    for root, dirs, files in os.walk(SAVE_DIR):\n",
    "        level = root.replace(SAVE_DIR, '').count(os.sep)\n",
    "        indent = '  ' * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        sub_indent = '  ' * (level + 1)\n",
    "        for file in files:\n",
    "            size = os.path.getsize(os.path.join(root, file)) / (1024*1024)\n",
    "            print(f\"{sub_indent}{file} ({size:.1f} MB)\")\n",
    "    \n",
    "    # Check for best checkpoint\n",
    "    best_pt = os.path.join(SAVE_DIR, 'best.pt')\n",
    "    if os.path.exists(best_pt):\n",
    "        size = os.path.getsize(best_pt) / (1024*1024)\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nüèÜ Best Model: {best_pt}\")\n",
    "        print(f\"üì¶ Size: {size:.1f} MB\")\n",
    "        print(f\"\\nüì• DOWNLOAD: Check 'Output' section in right sidebar ‚Üí\")\n",
    "        print(f\"üéØ Expected Performance: 70-72% mAP@50:95\")\n",
    "        print(f\"\\nüéâ Success! Model ready for deployment!\")\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  best.pt not found - check if training completed\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Results not found: {SAVE_DIR}\")\n",
    "    print(\"Training may have failed or not started.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
