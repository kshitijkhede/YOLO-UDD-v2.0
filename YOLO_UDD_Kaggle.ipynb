{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a82cd800",
   "metadata": {},
   "source": [
    "# \ud83c\udf0a YOLO-UDD v2.0 - Kaggle Training\n",
    "\n",
    "**Simple 6-Step Training - No Crashes, No Loops!** \u26a1\n",
    "\n",
    "## \ud83d\udccb Before You Start:\n",
    "1. **Enable GPU**: Settings \u2192 Accelerator \u2192 **GPU T4 x2** \u2192 Save\n",
    "2. **Dataset**: Google Drive link already configured (automatic download)\n",
    "3. **Run**: Execute cells 1-6 in order OR click \"Run All\"\n",
    "\n",
    "## \u23f1\ufe0f Training Info:\n",
    "- **Time**: ~10 hours (100 epochs)\n",
    "- **Expected mAP**: 70-72%\n",
    "- **No restarts needed!** \u2705\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830adbe",
   "metadata": {},
   "source": [
    "## Cell 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38942eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete environment setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udd27 CELL 1: Environment Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check and fix NumPy version FIRST (before any other imports)\n",
    "print(\"\\n[Step 1/3] Checking NumPy version...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_ver = np.__version__\n",
    "    \n",
    "    if numpy_ver.startswith('2.'):\n",
    "        print(f\"  \u26a0\ufe0f  NumPy {numpy_ver} detected (will cause TensorFlow crashes)\")\n",
    "        print(\"  \ud83d\udd27 Installing NumPy 1.26.4...\")\n",
    "        \n",
    "        # Use pip directly with quiet mode\n",
    "        !pip uninstall -y numpy > /dev/null 2>&1\n",
    "        !pip install -q numpy==1.26.4\n",
    "        \n",
    "        print(\"  \u2705 NumPy 1.26.4 installed\")\n",
    "        print(\"  \u2139\ufe0f  If you see import errors later, just re-run this cell\")\n",
    "    else:\n",
    "        print(f\"  \u2705 NumPy {numpy_ver} OK\")\n",
    "except Exception as e:\n",
    "    print(f\"  \u26a0\ufe0f  NumPy check issue: {e}\")\n",
    "    print(\"  \ud83d\udce6 Installing NumPy 1.26.4...\")\n",
    "    !pip install -q numpy==1.26.4\n",
    "    print(\"  \u2705 Installed\")\n",
    "\n",
    "# Setup directories\n",
    "print(\"\\n[Step 2/3] Setting up directories...\")\n",
    "WORK_DIR = '/kaggle/working'\n",
    "REPO_DIR = f'{WORK_DIR}/YOLO-UDD-v2.0'\n",
    "\n",
    "os.chdir(WORK_DIR)\n",
    "print(f\"  \u2705 Working directory: {WORK_DIR}\")\n",
    "\n",
    "# Clone repository\n",
    "print(\"\\n[Step 3/3] Cloning repository...\")\n",
    "if os.path.exists(REPO_DIR):\n",
    "    import shutil\n",
    "    shutil.rmtree(REPO_DIR)\n",
    "\n",
    "!git clone -q https://github.com/kshitijkhede/YOLO-UDD-v2.0.git\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    os.chdir(REPO_DIR)\n",
    "    if REPO_DIR not in sys.path:\n",
    "        sys.path.insert(0, REPO_DIR)\n",
    "    print(f\"  \u2705 Repository ready: {REPO_DIR}\")\n",
    "else:\n",
    "    raise Exception(\"Clone failed!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2705 Cell 1 Complete - Environment Ready!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42fbc1c",
   "metadata": {},
   "source": [
    "## Cell 2: Verify & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify setup and install dependencies",
    "import os",
    "import torch",
    "",
    "print(\"=\"*70)",
    "print(\"\ufffd\ufffd CELL 2: Verification & Dependencies\")",
    "print(\"=\"*70)",
    "",
    "# Verify repository structure",
    "print(\"\\n[Step 1/4] Verifying repository...\")",
    "required = ['models/', 'scripts/', 'utils/', 'configs/', 'scripts/train.py']",
    "all_ok = True",
    "for item in required:",
    "    if os.path.exists(item):",
    "        print(f\"  \u2705 {item}\")",
    "    else:",
    "        print(f\"  \u274c {item} MISSING\")",
    "        all_ok = False",
    "",
    "if not all_ok:",
    "    raise Exception(\"Repository incomplete! Re-run Cell 1\")",
    "",
    "# Check GPU",
    "print(\"\\n[Step 2/4] Checking GPU...\")",
    "if torch.cuda.is_available():",
    "    print(f\"  \u2705 GPU: {torch.cuda.get_device_name(0)}\")",
    "    print(f\"  \u2705 Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")",
    "else:",
    "    print(\"  \u274c NO GPU! Enable: Settings \u2192 GPU T4 x2\")",
    "    raise RuntimeError(\"GPU required!\")",
    "",
    "# Verify NumPy version",
    "print(\"\\n[Step 3/4] Verifying NumPy...\")",
    "import numpy as np",
    "print(f\"  \ud83d\udce6 NumPy version: {np.__version__}\")",
    "if np.__version__.startswith('2.'):",
    "    print(f\"  \u274c ERROR: NumPy {np.__version__} still active!\")",
    "    print(f\"  \ud83d\udd27 FIX: Re-run Cell 1, then restart kernel\")",
    "    raise RuntimeError(\"NumPy 2.x detected! Re-run Cell 1 and restart kernel.\")",
    "else:",
    "    print(f\"  \u2705 NumPy {np.__version__} OK\")",
    "",
    "# Install dependencies - FORCE REINSTALL to rebuild against NumPy 1.x",
    "print(\"\\n[Step 4/4] Installing dependencies (takes ~3 min)...\")",
    "print(\"  \ud83d\udd27 Force reinstalling packages to rebuild against NumPy 1.26.4...\")",
    "",
    "# Uninstall problematic packages first",
    "!pip uninstall -y tensorboard tensorflow keras scikit-learn matplotlib > /dev/null 2>&1",
    "",
    "# Install with force reinstall to rebuild against NumPy 1.x",
    "!pip install -q --force-reinstall --no-cache-dir tensorboard scikit-learn matplotlib seaborn",
    "!pip install -q torch>=2.0.0 torchvision>=0.15.0 albumentations>=1.3.0 \\",
    "    opencv-python-headless>=4.7.0 pycocotools>=2.0.6 tqdm pyyaml",
    "",
    "print(\"  \u2705 All dependencies installed and rebuilt against NumPy 1.26.4\")",
    "",
    "print(\"\\n\" + \"=\"*70)",
    "print(\"\u2705 Cell 2 Complete - System Ready!\")",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc8028",
   "metadata": {},
   "source": [
    "## Cell 3: Setup Dataset\n",
    "\n",
    "**Dataset will download automatically from Google Drive (~170 MB, takes 2-3 min)**\n",
    "\n",
    "Alternative: Upload your own dataset to Kaggle and set `USE_KAGGLE_DATASET = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset setup\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udce6 CELL 3: Dataset Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "USE_KAGGLE_DATASET = False  # Set True if you added dataset to Kaggle\n",
    "KAGGLE_DATASET_PATH = '/kaggle/input/trashcan-dataset'\n",
    "\n",
    "USE_GDRIVE = True  # \u2705 Default: Download from Google Drive\n",
    "GDRIVE_FILE_ID = '10PCbGqgVi0-XQn0EfGTTfSjwNS0JXR99'\n",
    "# ============================================\n",
    "\n",
    "DATASET_PATH = None\n",
    "\n",
    "if USE_KAGGLE_DATASET:\n",
    "    print(\"\\n\ud83d\udcc2 Using Kaggle Dataset...\")\n",
    "    if os.path.exists(KAGGLE_DATASET_PATH):\n",
    "        if os.path.isfile(KAGGLE_DATASET_PATH):\n",
    "            print(\"  \ud83d\udce6 Extracting...\")\n",
    "            !unzip -q {KAGGLE_DATASET_PATH} -d /kaggle/working/\n",
    "            DATASET_PATH = '/kaggle/working/trashcan'\n",
    "        else:\n",
    "            trashcan = os.path.join(KAGGLE_DATASET_PATH, 'trashcan')\n",
    "            DATASET_PATH = trashcan if os.path.exists(trashcan) else KAGGLE_DATASET_PATH\n",
    "        print(f\"  \u2705 Dataset: {DATASET_PATH}\")\n",
    "    else:\n",
    "        print(f\"  \u274c NOT FOUND: {KAGGLE_DATASET_PATH}\")\n",
    "\n",
    "elif USE_GDRIVE:\n",
    "    print(\"\\n\u2601\ufe0f  Downloading from Google Drive...\")\n",
    "    print(\"  \ud83d\udce6 Installing gdown...\")\n",
    "    !pip install -q gdown\n",
    "    \n",
    "    print(\"  \u2b07\ufe0f  Downloading dataset (~170 MB, 2-3 min)...\")\n",
    "    !gdown --id {GDRIVE_FILE_ID} -O /kaggle/working/trashcan.zip --quiet\n",
    "    \n",
    "    if os.path.exists('/kaggle/working/trashcan.zip'):\n",
    "        size = os.path.getsize('/kaggle/working/trashcan.zip') / 1024 / 1024\n",
    "        print(f\"  \u2705 Downloaded: {size:.1f} MB\")\n",
    "        \n",
    "        print(\"  \ud83d\udce6 Extracting...\")\n",
    "        !unzip -q /kaggle/working/trashcan.zip -d /kaggle/working/\n",
    "        \n",
    "        if os.path.exists('/kaggle/working/trashcan'):\n",
    "            DATASET_PATH = '/kaggle/working/trashcan'\n",
    "            print(f\"  \u2705 Dataset: {DATASET_PATH}\")\n",
    "        else:\n",
    "            print(\"  \u274c Extraction failed\")\n",
    "    else:\n",
    "        print(\"  \u274c Download failed\")\n",
    "else:\n",
    "    print(\"\\n\u274c No method selected! Set USE_KAGGLE_DATASET or USE_GDRIVE = True\")\n",
    "\n",
    "# Verify dataset\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if DATASET_PATH and os.path.exists(DATASET_PATH):\n",
    "    print(f\"\u2705 DATASET READY: {DATASET_PATH}\")\n",
    "    \n",
    "    # Count images\n",
    "    if os.path.exists(os.path.join(DATASET_PATH, 'images')):\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            img_path = os.path.join(DATASET_PATH, 'images', split)\n",
    "            if os.path.exists(img_path):\n",
    "                count = len([f for f in os.listdir(img_path) if f.endswith(('.jpg', '.png'))])\n",
    "                print(f\"  \ud83d\udcc1 {split}: {count:,} images\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\u2705 Cell 3 Complete - Dataset Ready!\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\u274c DATASET NOT READY!\")\n",
    "    raise Exception(\"Dataset setup failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5b365",
   "metadata": {},
   "source": [
    "## Cell 4: Build & Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ee2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and test YOLO-UDD model\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83c\udfd7\ufe0f  CELL 4: Build Model\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ensure correct paths\n",
    "REPO_DIR = '/kaggle/working/YOLO-UDD-v2.0'\n",
    "os.chdir(REPO_DIR)\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "print(\"\\n[Step 1/2] Building model...\")\n",
    "from models.yolo_udd import build_yolo_udd\n",
    "\n",
    "model = build_yolo_udd(num_classes=22)  # TrashCAN has 22 classes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"  \u2705 Model: YOLO-UDD v2.0\")\n",
    "print(f\"  \u2705 Classes: 22\")\n",
    "print(f\"  \u2705 Device: {device}\")\n",
    "print(f\"  \u2705 Parameters: {total_params:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\n[Step 2/2] Testing model...\")\n",
    "x = torch.randn(1, 3, 640, 640).to(device)\n",
    "with torch.no_grad():\n",
    "    predictions, turb_score = model(x)\n",
    "\n",
    "print(f\"  \u2705 Forward pass successful\")\n",
    "print(f\"  \u2705 Turbidity score: {turb_score.item():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2705 Cell 4 Complete - Model Ready!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f0baad",
   "metadata": {},
   "source": [
    "## Cell 5: Start Training \u26a1\n",
    "\n",
    "**\u23f1\ufe0f This will take ~10 hours for 100 epochs**\n",
    "\n",
    "Training automatically:\n",
    "- Saves checkpoints every epoch\n",
    "- Shows progress with progress bar\n",
    "- Saves best model as `best.pt`\n",
    "- Results saved to `/kaggle/working/runs/train/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82fa8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and start training\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\ude80 CELL 5: TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Training configuration\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.01\n",
    "SAVE_DIR = '/kaggle/working/runs/train'\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Configuration:\")\n",
    "print(f\"  \u2022 Epochs: {EPOCHS}\")\n",
    "print(f\"  \u2022 Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  \u2022 Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  \u2022 Dataset: {DATASET_PATH}\")\n",
    "print(f\"  \u2022 Save Dir: {SAVE_DIR}\")\n",
    "print(f\"\\n\u23f1\ufe0f  Estimated Time: ~10 hours\")\n",
    "print(f\"\ud83c\udfaf Expected mAP: 70-72%\")\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\ud83d\ude80 TRAINING STARTING...\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Run training with correct arguments\n",
    "!python scripts/train.py \\\n",
    "    --config configs/train_config.yaml \\\n",
    "    --data-dir {DATASET_PATH} \\\n",
    "    --epochs {EPOCHS} \\\n",
    "    --batch-size {BATCH_SIZE} \\\n",
    "    --lr {LEARNING_RATE} \\\n",
    "    --save-dir {SAVE_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701bf285",
   "metadata": {},
   "source": [
    "## Cell 6: Check Results & Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udcca CELL 6: Results\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if os.path.exists(SAVE_DIR):\n",
    "    print(f\"\\n\ud83d\udcc1 Results: {SAVE_DIR}\\n\")\n",
    "    \n",
    "    # List files\n",
    "    for root, dirs, files in os.walk(SAVE_DIR):\n",
    "        level = root.replace(SAVE_DIR, '').count(os.sep)\n",
    "        indent = '  ' * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        sub_indent = '  ' * (level + 1)\n",
    "        for file in files:\n",
    "            size = os.path.getsize(os.path.join(root, file)) / (1024*1024)\n",
    "            print(f\"{sub_indent}{file} ({size:.1f} MB)\")\n",
    "    \n",
    "    # Check for best checkpoint\n",
    "    best_pt = os.path.join(SAVE_DIR, 'best.pt')\n",
    "    if os.path.exists(best_pt):\n",
    "        size = os.path.getsize(best_pt) / (1024*1024)\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"\u2705 TRAINING COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\n\ud83c\udfc6 Best Model: {best_pt}\")\n",
    "        print(f\"\ud83d\udce6 Size: {size:.1f} MB\")\n",
    "        print(f\"\\n\ud83d\udce5 DOWNLOAD: Check 'Output' section in right sidebar \u2192\")\n",
    "        print(f\"\ud83c\udfaf Expected Performance: 70-72% mAP@50:95\")\n",
    "        print(f\"\\n\ud83c\udf89 Success! Model ready for deployment!\")\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(\"\\n\u26a0\ufe0f  best.pt not found - check if training completed\")\n",
    "else:\n",
    "    print(f\"\\n\u274c Results not found: {SAVE_DIR}\")\n",
    "    print(\"Training may have failed or not started.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}