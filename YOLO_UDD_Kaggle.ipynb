{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# \ud83c\udf0a YOLO-UDD v2.0 - Kaggle Training\n",
    "\n",
    "**Simple 6-Cell Training - Just Run All!** \u26a1\n",
    "\n",
    "## \ud83d\udccb Before You Start:\n",
    "1. **Enable GPU**: Settings \u2192 Accelerator \u2192 **GPU T4 x2** \u2192 Save\n",
    "2. **Dataset**: Google Drive link already configured (automatic download)\n",
    "3. **Run**: Click **\"Run All\"** and wait ~10 hours\n",
    "\n",
    "## \u23f1\ufe0f Training Info:\n",
    "- **Time**: ~10 hours (100 epochs)\n",
    "- **Expected mAP**: 70-72%\n",
    "- **No restarts needed!** \u2705\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell1",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# \ud83d\udce6 CELL 1: Environment Setup\n",
    "# ======================================================================\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udd27 CELL 1: Environment Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check and fix NumPy version FIRST\n",
    "print(\"\\n[Step 1/3] Checking NumPy version...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_ver = np.__version__\n",
    "    \n",
    "    if numpy_ver.startswith('2.'):\n",
    "        print(f\"  \u26a0\ufe0f  NumPy {numpy_ver} detected (will cause crashes)\")\n",
    "        print(\"  \ud83d\udd27 Installing NumPy 1.26.4...\")\n",
    "        !pip uninstall -y numpy > /dev/null 2>&1\n",
    "        !pip install -q numpy==1.26.4\n",
    "        print(\"  \u2705 NumPy 1.26.4 installed\")\n",
    "    else:\n",
    "        print(f\"  \u2705 NumPy {numpy_ver} OK\")\n",
    "except Exception as e:\n",
    "    print(f\"  \u26a0\ufe0f  NumPy check issue: {e}\")\n",
    "    !pip install -q numpy==1.26.4\n",
    "\n",
    "# Set working directory\n",
    "print(\"\\n[Step 2/3] Setting up workspace...\")\n",
    "WORK_DIR = '/kaggle/working'\n",
    "REPO_DIR = '/kaggle/working/YOLO-UDD-v2.0'\n",
    "os.chdir(WORK_DIR)\n",
    "print(f\"  \u2705 Working directory: {WORK_DIR}\")\n",
    "\n",
    "# Clone repository\n",
    "print(\"\\n[Step 3/3] Cloning repository...\")\n",
    "if os.path.exists(REPO_DIR):\n",
    "    import shutil\n",
    "    shutil.rmtree(REPO_DIR)\n",
    "\n",
    "!git clone -q https://github.com/kshitijkhede/YOLO-UDD-v2.0.git\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    os.chdir(REPO_DIR)\n",
    "    if REPO_DIR not in sys.path:\n",
    "        sys.path.insert(0, REPO_DIR)\n",
    "    print(f\"  \u2705 Repository ready: {REPO_DIR}\")\n",
    "else:\n",
    "    raise Exception(\"Clone failed!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2705 Cell 1 Complete - Environment Ready!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell2",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# \ud83d\udce6 CELL 2: Verification & Dependencies\n",
    "# ======================================================================\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udce6 CELL 2: Verification & Dependencies\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ensure we're in the repository\n",
    "REPO_DIR = '/kaggle/working/YOLO-UDD-v2.0'\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(f\"\\n\u274c Repository not found at {REPO_DIR}\")\n",
    "    print(\"\u26a0\ufe0f  Please re-run Cell 1\")\n",
    "    raise Exception(\"Repository not found! Re-run Cell 1\")\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "# Verify repository structure\n",
    "print(\"\\n[Step 1/3] Verifying repository...\")\n",
    "required = ['models/', 'scripts/', 'utils/', 'configs/', 'data/', 'scripts/train.py']\n",
    "all_ok = True\n",
    "for item in required:\n",
    "    if os.path.exists(item):\n",
    "        print(f\"  \u2705 {item}\")\n",
    "    else:\n",
    "        print(f\"  \u274c {item} MISSING\")\n",
    "        all_ok = False\n",
    "\n",
    "if not all_ok:\n",
    "    raise Exception(\"Repository incomplete! Re-run Cell 1\")\n",
    "\n",
    "# Check GPU\n",
    "print(\"\\n[Step 2/3] Checking GPU...\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  \u2705 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  \u2705 Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"  \u26a0\ufe0f  NO GPU! Enable: Settings \u2192 GPU T4 x2\")\n",
    "\n",
    "# Install dependencies\n",
    "print(\"\\n[Step 3/3] Installing dependencies (~2 min)...\")\n",
    "!pip install -q torch>=2.0.0 torchvision>=0.15.0 albumentations>=1.3.0 \\\n",
    "    opencv-python-headless>=4.7.0 pycocotools>=2.0.6 tensorboard>=2.12.0 \\\n",
    "    tqdm pyyaml scikit-learn matplotlib seaborn gdown\n",
    "\n",
    "print(\"  \u2705 Dependencies installed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2705 Cell 2 Complete - System Ready!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell3",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# \ud83d\udce6 CELL 3: Dataset Setup\n",
    "# ======================================================================\n",
    "import os\n",
    "import gdown\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udce6 CELL 3: Dataset Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Download from Google Drive\n",
    "FILE_ID = '17oRYriPgBnW9zowwmhImxdUpmHwOjgIp'\n",
    "GDRIVE_URL = f'https://drive.google.com/uc?id={FILE_ID}'\n",
    "ZIP_PATH = '/kaggle/working/trashcan.zip'\n",
    "\n",
    "print(\"\\n\u2601\ufe0f  Downloading dataset from Google Drive (~180 MB)...\")\n",
    "gdown.download(GDRIVE_URL, ZIP_PATH, quiet=False)\n",
    "\n",
    "if os.path.exists(ZIP_PATH):\n",
    "    size = os.path.getsize(ZIP_PATH) / (1024 * 1024)\n",
    "    print(f\"  \u2705 Downloaded: {size:.1f} MB\")\n",
    "    \n",
    "    print(\"  \ud83d\udce6 Extracting...\")\n",
    "    # Extract using Python zipfile (handles Windows paths better)\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall('/kaggle/working/')\n",
    "    print(\"  \u2705 Extracted\")\n",
    "    \n",
    "    # Show what was extracted\n",
    "    print(\"\\n\ud83d\udd0d Checking extracted contents...\")\n",
    "    work_contents = [d for d in os.listdir('/kaggle/working/') if not d.startswith('.') and d != 'trashcan.zip']\n",
    "    print(f\"  Contents of /kaggle/working/: {work_contents}\")\n",
    "    \n",
    "    # Try multiple possible paths\n",
    "    possible_paths = [\n",
    "        '/kaggle/working/trashcan',\n",
    "        '/kaggle/working/trashcan/trashcan',\n",
    "        '/kaggle/working/data/trashcan',\n",
    "        '/kaggle/working'\n",
    "    ]\n",
    "    \n",
    "    DATASET_PATH = None\n",
    "    for path in possible_paths:\n",
    "        print(f\"  Checking: {path}\")\n",
    "        if os.path.exists(path):\n",
    "            # Check for images and annotations subdirectories\n",
    "            has_images = os.path.exists(os.path.join(path, 'images'))\n",
    "            has_annotations = os.path.exists(os.path.join(path, 'annotations'))\n",
    "            print(f\"    Path exists | images: {has_images} | annotations: {has_annotations}\")\n",
    "            \n",
    "            if has_images and has_annotations:\n",
    "                DATASET_PATH = path\n",
    "                print(f\"    \u2705 FOUND DATASET HERE!\")\n",
    "                break\n",
    "    \n",
    "    # If still not found, search for images/annotations directories\n",
    "    if not DATASET_PATH:\n",
    "        print(\"\\n\ud83d\udd0d Searching for dataset structure...\")\n",
    "        for root, dirs, files in os.walk('/kaggle/working/'):\n",
    "            if 'images' in dirs and 'annotations' in dirs:\n",
    "                DATASET_PATH = root\n",
    "                print(f\"  \u2705 Found dataset at: {DATASET_PATH}\")\n",
    "                break\n",
    "    \n",
    "    if DATASET_PATH:\n",
    "        print(f\"\\n\u2705 DATASET FOUND: {DATASET_PATH}\")\n",
    "        \n",
    "        # Verify structure\n",
    "        print(\"\\n\ud83d\udcc2 Dataset Structure:\")\n",
    "        images_dir = os.path.join(DATASET_PATH, 'images')\n",
    "        annotations_dir = os.path.join(DATASET_PATH, 'annotations')\n",
    "        \n",
    "        # Show image counts\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            img_path = os.path.join(images_dir, split)\n",
    "            if os.path.exists(img_path):\n",
    "                count = len([f for f in os.listdir(img_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "                print(f\"  \u2705 {split}: {count:,} images\")\n",
    "        \n",
    "        # Show annotations\n",
    "        if os.path.exists(annotations_dir):\n",
    "            json_files = [f for f in os.listdir(annotations_dir) if f.endswith('.json')]\n",
    "            for jf in json_files:\n",
    "                size = os.path.getsize(os.path.join(annotations_dir, jf)) / (1024 * 1024)\n",
    "                print(f\"  \u2705 {jf} ({size:.1f} MB)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"\u2705 Cell 3 Complete - Dataset Ready!\")\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(\"\\n\u274c Dataset not found!\")\n",
    "        print(\"\\nDebug - Complete directory tree:\")\n",
    "        for root, dirs, files in os.walk('/kaggle/working/'):\n",
    "            level = root.replace('/kaggle/working/', '').count(os.sep)\n",
    "            if level < 3:  # Limit depth\n",
    "                indent = '  ' * level\n",
    "                print(f\"{indent}{os.path.basename(root)}/\")\n",
    "                subindent = '  ' * (level + 1)\n",
    "                for d in dirs[:5]:\n",
    "                    print(f\"{subindent}{d}/\")\n",
    "                for f in files[:5]:\n",
    "                    print(f\"{subindent}{f}\")\n",
    "        raise Exception(\"Dataset not found after extraction!\")\n",
    "else:\n",
    "    raise Exception(\"Download failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell4",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# \ufffd\ufffd\ufe0f  CELL 4: Build Model\n",
    "# ======================================================================\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83c\udfd7\ufe0f  CELL 4: Build Model\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ensure correct paths\n",
    "REPO_DIR = '/kaggle/working/YOLO-UDD-v2.0'\n",
    "os.chdir(REPO_DIR)\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "print(\"\\n[Step 1/2] Importing YOLO-UDD...\")\n",
    "from models.yolo_udd import YOLO_UDD\n",
    "print(\"  \u2705 YOLO-UDD imported\")\n",
    "\n",
    "print(\"\\n[Step 2/2] Building model...\")\n",
    "model = YOLO_UDD(num_classes=22, pretrained_backbone=True)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"  \u2705 Model built successfully\")\n",
    "print(f\"  \ud83d\udcca Total parameters: {total_params:,}\")\n",
    "print(f\"  \ud83d\udcca Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\n[Test] Forward pass...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "dummy_input = torch.randn(1, 3, 640, 640).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "print(f\"  \u2705 Output shape: {output.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2705 Cell 4 Complete - Model Ready!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell5",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# \ud83d\ude80 CELL 5: Start Training\n",
    "# ======================================================================\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\ude80 CELL 5: Training (will take ~10 hours)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ensure we're in the repository\n",
    "REPO_DIR = '/kaggle/working/YOLO-UDD-v2.0'\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "# Training command\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    'scripts/train.py',\n",
    "    '--data_dir', '/kaggle/working/trashcan',\n",
    "    '--config', 'configs/train_config.yaml',\n",
    "    '--output_dir', '/kaggle/working/runs/training',\n",
    "    '--epochs', '100',\n",
    "    '--batch_size', '8'\n",
    "]\n",
    "\n",
    "print(\"\\n\ud83d\udcdd Training Configuration:\")\n",
    "print(f\"  Dataset: /kaggle/working/trashcan\")\n",
    "print(f\"  Epochs: 100\")\n",
    "print(f\"  Batch size: 8\")\n",
    "print(f\"  Output: /kaggle/working/runs/training\")\n",
    "\n",
    "print(\"\\n\ud83c\udfc3 Starting training...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Run training\n",
    "result = subprocess.run(cmd, capture_output=False, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\u2705 Cell 5 Complete - Training Finished!\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\u274c Training failed!\")\n",
    "    print(\"=\"*70)\n",
    "    raise Exception(f\"Training failed with code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell6",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# \ud83d\udcca CELL 6: Results & Download\n",
    "# ======================================================================\n",
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udcca CELL 6: Results\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check for checkpoints\n",
    "checkpoint_dir = '/kaggle/working/runs/training/checkpoints'\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pt')]\n",
    "    \n",
    "    if checkpoints:\n",
    "        print(\"\\n\u2705 Training completed successfully!\\n\")\n",
    "        print(\"\ud83d\udce6 Available checkpoints:\")\n",
    "        for ckpt in sorted(checkpoints):\n",
    "            path = os.path.join(checkpoint_dir, ckpt)\n",
    "            size = os.path.getsize(path) / (1024 * 1024)\n",
    "            print(f\"  \u2022 {ckpt} ({size:.1f} MB)\")\n",
    "        \n",
    "        # Show best checkpoint\n",
    "        best_ckpt = os.path.join(checkpoint_dir, 'best.pt')\n",
    "        if os.path.exists(best_ckpt):\n",
    "            print(f\"\\n\u2b50 Best checkpoint: {best_ckpt}\")\n",
    "        \n",
    "        print(\"\\n\ud83d\udca1 To download: Click the folder icon on left \u2192 Navigate to checkpoints \u2192 Download\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"\ud83c\udf89 ALL DONE! Training Complete!\")\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(\"\\n\u26a0\ufe0f  No checkpoints found\")\n",
    "else:\n",
    "    print(\"\\n\u274c Checkpoint directory not found\")\n",
    "    print(\"Check if training completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}