â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 ğŸš€ KAGGLE QUICK START - YOLO-UDD v2.0                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ BEFORE YOU START:
  1. Create Kaggle account: https://www.kaggle.com/
  2. Have annotation files ready:
     - train.json (22 MB)
     - val.json (5.6 MB)
     Located at: /home/student/MIR/Project/YOLO-UDD-v2.0/data/trashcan/annotations/

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ METHOD 1: Using Kaggle Dataset (RECOMMENDED)

STEP 1: Upload Annotations to Kaggle
  1.1. Zip annotations:
       $ cd /home/student/MIR/Project/YOLO-UDD-v2.0/data/trashcan/annotations
       $ zip annotations.zip train.json val.json
  
  1.2. Upload to Kaggle:
       â€¢ Go to: https://www.kaggle.com/datasets
       â€¢ Click "New Dataset"
       â€¢ Upload annotations.zip
       â€¢ Title: "TrashCAN Annotations COCO Format"
       â€¢ Note your dataset path: YOUR_USERNAME/trashcan-annotations-coco-format

STEP 2: Create Notebook
  2.1. Go to: https://www.kaggle.com/code
  2.2. Click "New Notebook"
  2.3. Settings â†’ Accelerator â†’ GPU P100 or T4 âš¡
  2.4. Settings â†’ Internet â†’ ON ğŸŒ

STEP 3: Add Your Dataset
  3.1. Click "+ Add Data" (right sidebar)
  3.2. Search: YOUR_USERNAME/trashcan-annotations-coco-format
  3.3. Click "Add"

STEP 4: Copy Training Code
  4.1. Open: KAGGLE_SETUP_GUIDE.md
  4.2. Copy cells from "Step 5: Run Training Code"
  4.3. Paste into Kaggle notebook
  4.4. Update paths in Cell 4 to match your dataset

STEP 5: Run All Cells
  5.1. Click "Run All" or run cells one by one
  5.2. Wait for training to complete (~6 hours for 100 epochs)
  5.3. Download checkpoints from /kaggle/working/checkpoints/

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ METHOD 2: Direct Upload (Simpler but requires re-upload each session)

STEP 1-2: Same as Method 1 (Create notebook, enable GPU)

STEP 3: Upload Files Directly
  3.1. In first notebook cell, run:
       from google.colab import files
       import os
       os.makedirs('data/trashcan/annotations', exist_ok=True)
       
       print("Upload train.json...")
       uploaded = files.upload()
       !mv train.json data/trashcan/annotations/
       
       print("Upload val.json...")
       uploaded = files.upload()
       !mv val.json data/trashcan/annotations/
  
  3.2. When prompted, upload train.json then val.json

STEP 4-5: Continue from Method 1, Step 4

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â±ï¸  EXPECTED TIMELINE:

Session 1 (100 epochs, ~6 hours):
  â€¢ Epoch 0-25:  Loss 2.5â†’1.5, mAP ~25-30%
  â€¢ Epoch 25-50:  Loss 1.5â†’1.2, mAP ~40-45%
  â€¢ Epoch 50-75:  Loss 1.2â†’0.9, mAP ~50-55%
  â€¢ Epoch 75-100: Loss 0.9â†’0.7, mAP ~55-60%

Session 2 (100 epochs, ~6 hours):
  â€¢ mAP: 60% â†’ 65-70%

Session 3 (100 epochs, ~6 hours):
  â€¢ mAP: 70% â†’ 70-75% âœ… PRODUCTION READY!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”§ QUICK TROUBLESHOOTING:

âŒ "CUDA out of memory"
   â†’ Reduce batch size to 8 or 4 in config

âŒ "Annotation files not found"
   â†’ Check dataset path: !ls -la /kaggle/input/
   â†’ Adjust paths in Cell 4

âŒ "Training slow"
   â†’ Verify GPU enabled: import torch; print(torch.cuda.is_available())
   â†’ Should print: True

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“¥ DOWNLOAD RESULTS:

Checkpoints saved at: /kaggle/working/checkpoints/
  â€¢ best.pth - Best model (highest mAP)
  â€¢ last.pth - Most recent model
  â€¢ epoch_*.pth - Checkpoints every 10 epochs

To download:
  1. Click "Output" tab (top right)
  2. Navigate to checkpoints/
  3. Click download icon

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… SUCCESS INDICATORS:

âœ“ GPU detected (Cell 3 shows CUDA available)
âœ“ Annotations loaded (shows image/annotation counts)
âœ“ Training starts without errors
âœ“ Loss decreases each epoch
âœ“ Checkpoints save to /kaggle/working/checkpoints/
âœ“ After 100 epochs: mAP@50 > 55%

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“š FULL DOCUMENTATION:

â€¢ Complete guide: KAGGLE_SETUP_GUIDE.md
â€¢ Training notebook: YOLO_UDD_Kaggle_Training.ipynb
â€¢ Cloud guide: CLOUD_TRAINING_GUIDE.md
â€¢ Quick start: QUICKSTART.md

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ï¿½ï¿½ LINKS:

â€¢ GitHub: https://github.com/kshitijkhede/YOLO-UDD-v2.0
â€¢ Kaggle: https://www.kaggle.com/
â€¢ Kaggle Datasets: https://www.kaggle.com/datasets
â€¢ Kaggle Notebooks: https://www.kaggle.com/code

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ‰ YOU'RE ALL SET! Follow Method 1 above and you'll be training in minutes!

